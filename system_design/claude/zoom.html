<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>System Design: Zoom</title>
<style>
body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background: #0f0f0f; color: #e0e0e0; line-height: 1.7; }
h1 { color: #00aaff; border-bottom: 3px solid #00aaff; padding-bottom: 10px; font-size: 2.2em; }
h2 { color: #00ccff; margin-top: 40px; font-size: 1.6em; border-left: 4px solid #00ccff; padding-left: 12px; }
h3 { color: #66ddff; font-size: 1.3em; }
h4 { color: #88eeff; }
.section { background: #1a1a2e; border-radius: 10px; padding: 25px; margin: 20px 0; border: 1px solid #333; }
.diagram-container { background: #0d1117; border-radius: 10px; padding: 20px; margin: 20px 0; text-align: center; overflow-x: auto; }
.example { background: #1e293b; border-left: 4px solid #f59e0b; padding: 15px 20px; margin: 15px 0; border-radius: 0 8px 8px 0; }
.example strong { color: #f59e0b; }
table { width: 100%; border-collapse: collapse; margin: 15px 0; }
th { background: #2a2a4a; color: #00ccff; padding: 12px; text-align: left; border: 1px solid #444; }
td { padding: 10px 12px; border: 1px solid #333; }
tr:nth-child(even) { background: #1a1a2e; }
tr:nth-child(odd) { background: #151528; }
code { background: #2d2d4d; padding: 2px 8px; border-radius: 4px; color: #ff79c6; font-size: 0.95em; }
.tag { display: inline-block; padding: 3px 10px; border-radius: 12px; font-size: 0.8em; margin: 2px; }
.tag-pk { background: #4a1a6b; color: #d4a5ff; }
.tag-fk { background: #1a4a3b; color: #a5ffd4; }
.tag-idx { background: #4a3a1a; color: #ffd4a5; }
.tag-shard { background: #1a2a4a; color: #a5d4ff; }
ul { padding-left: 25px; }
li { margin: 5px 0; }
.tradeoff { display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin: 15px 0; }
.pro { background: #0a2a1a; border: 1px solid #2a5a3a; padding: 15px; border-radius: 8px; }
.con { background: #2a0a1a; border: 1px solid #5a2a3a; padding: 15px; border-radius: 8px; }
</style>
</head>
<body>
<h1>System Design: Zoom (Video Conferencing)</h1>

<div class="section">
<h2>Functional Requirements</h2>
<ul>
<li>Users can create and schedule video meetings with unique meeting IDs</li>
<li>Users can join meetings via link or meeting ID + passcode</li>
<li>Real-time video and audio streaming between participants (up to 1000 in a meeting)</li>
<li>Screen sharing capability</li>
<li>Real-time text chat within meetings</li>
<li>Meeting recording and cloud storage</li>
<li>Virtual waiting room and host controls (mute, remove, admit)</li>
</ul>
</div>

<div class="section">
<h2>Non-Functional Requirements</h2>
<ul>
<li><strong>Low Latency:</strong> &lt;150ms end-to-end for audio/video (real-time requirement)</li>
<li><strong>High Availability:</strong> 99.99% uptime for signaling servers</li>
<li><strong>Scalability:</strong> Support millions of concurrent meetings, each up to 1000 participants</li>
<li><strong>Quality Adaptation:</strong> Adaptive bitrate based on network conditions</li>
<li><strong>Security:</strong> End-to-end encryption option, AES-256-GCM for media</li>
<li><strong>Reliability:</strong> Graceful degradation (audio priority over video on bad networks)</li>
</ul>
</div>

<!-- Flow 1: Creating/Joining a Meeting -->
<div class="section">
<h2>Flow 1: Creating & Joining a Meeting (Signaling)</h2>
<div class="diagram-container">
<svg viewBox="0 0 1100 500" xmlns="http://www.w3.org/2000/svg">
<defs><marker id="arrow1" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto"><polygon points="0 0, 10 3.5, 0 7" fill="#00aaff"/></marker></defs>
<rect x="20" y="200" width="120" height="60" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="80" y="235" text-anchor="middle" fill="white" font-size="14">Host Client</text>
<rect x="200" y="200" width="140" height="60" rx="10" fill="#e76f51" stroke="#ff9a76" stroke-width="2"/><text x="270" y="228" text-anchor="middle" fill="white" font-size="13">API Gateway /</text><text x="270" y="245" text-anchor="middle" fill="white" font-size="13">Load Balancer</text>
<rect x="400" y="120" width="140" height="60" rx="10" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="470" y="155" text-anchor="middle" fill="white" font-size="13">Meeting Service</text>
<rect x="400" y="280" width="140" height="60" rx="10" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="470" y="308" text-anchor="middle" fill="white" font-size="12">Signaling Service</text><text x="470" y="325" text-anchor="middle" fill="white" font-size="11">(WebSocket)</text>
<rect x="620" y="120" width="130" height="50" rx="8" fill="#8338ec" stroke="#b06efd" stroke-width="2"/><text x="685" y="150" text-anchor="middle" fill="white" font-size="13">SFU Router</text>
<path d="M 620 310 Q 685 310 685 190 Q 685 170 685 170" stroke="#00aaff" stroke-width="2" fill="none" marker-end="url(#arrow1)"/>
<ellipse cx="470" cy="430" rx="70" ry="30" fill="#6b2fa0" stroke="#9d5fd0" stroke-width="2"/><text x="470" y="435" text-anchor="middle" fill="white" font-size="12">Meeting DB</text>
<rect x="640" y="280" width="120" height="50" rx="8" fill="#c77dba" stroke="#e0a5d8" stroke-width="2"/><text x="700" y="310" text-anchor="middle" fill="white" font-size="12">TURN/STUN</text>
<rect x="820" y="200" width="120" height="60" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="880" y="228" text-anchor="middle" fill="white" font-size="13">Participant</text><text x="880" y="245" text-anchor="middle" fill="white" font-size="13">Clients</text>
<rect x="820" y="80" width="140" height="50" rx="8" fill="#1e6091" stroke="#3a8cbf" stroke-width="2"/><text x="890" y="110" text-anchor="middle" fill="white" font-size="12">Media Server (SFU)</text>
<line x1="140" y1="230" x2="198" y2="230" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow1)"/>
<line x1="340" y1="215" x2="398" y2="155" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow1)"/>
<line x1="340" y1="245" x2="398" y2="305" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow1)"/>
<line x1="470" y1="180" x2="470" y2="398" stroke="#ff6b6b" stroke-width="1.5" stroke-dasharray="5,5" marker-end="url(#arrow1)"/>
<line x1="540" y1="310" x2="638" y2="305" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow1)"/>
<line x1="750" y1="145" x2="818" y2="115" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow1)"/>
<line x1="760" y1="305" x2="818" y2="240" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow1)"/>
<line x1="890" y1="130" x2="890" y2="198" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow1)"/>
<text x="550" y="25" text-anchor="middle" fill="#aaa" font-size="16" font-weight="bold">Zoom: Meeting Creation & Join Flow</text>
</svg>
</div>

<h3>Step-by-Step</h3>
<ol>
<li><strong>Host creates meeting</strong> → POST to Meeting Service → generates unique meeting ID (11-digit numeric) + passcode → stores in Meeting DB</li>
<li><strong>Participant joins</strong> → enters meeting ID/passcode → Signaling Service authenticates via WebSocket</li>
<li><strong>Signaling exchange</strong> → SDP offer/answer + ICE candidates exchanged between client and SFU via Signaling Service</li>
<li><strong>NAT traversal</strong> → STUN discovers public IP; if symmetric NAT, falls back to TURN relay</li>
<li><strong>SFU Router</strong> assigns participant to optimal Media Server (SFU) based on geographic proximity and load</li>
<li><strong>Media flows</strong> → Each client sends 1 stream to SFU, SFU forwards N-1 streams to each participant (Selective Forwarding Unit)</li>
</ol>

<div class="example">
<strong>Example:</strong> Alice creates meeting ID 123-456-7890 with passcode "abc123". She shares the link. Bob clicks the link → WebSocket connects to Signaling Service → SDP exchange → STUN resolves Bob's public IP → Bob connects to SFU in us-east-1 → SFU starts forwarding Alice's video to Bob and Bob's video to Alice. Latency: ~80ms (same region).
</div>

<h3>Deep Dive: Signaling Service</h3>
<ul>
<li><strong>Protocol:</strong> WebSocket (WSS) for persistent bidirectional signaling</li>
<li><strong>Purpose:</strong> Exchange SDP offers/answers, ICE candidates, join/leave events, mute/unmute signals</li>
<li><strong>Input:</strong> <code>{ type: "join", meeting_id: "123-456-7890", sdp_offer: "..." }</code></li>
<li><strong>Output:</strong> <code>{ type: "sdp_answer", sdp: "...", ice_candidates: [...] }</code></li>
<li><strong>Scale:</strong> Stateless signaling servers behind L4 load balancer with sticky sessions (WebSocket affinity)</li>
</ul>

<h3>Deep Dive: SFU (Selective Forwarding Unit)</h3>
<ul>
<li><strong>Protocol:</strong> WebRTC (SRTP over UDP for media, DTLS for key exchange)</li>
<li><strong>Why SFU over Mesh:</strong> Mesh = O(N²) connections; SFU = O(N). For 10 participants, mesh needs 90 streams vs SFU needs 10 upload + 10×9 download handled server-side</li>
<li><strong>Simulcast:</strong> Each client sends 3 quality layers (high/medium/low); SFU selects appropriate layer per receiver based on their bandwidth</li>
<li><strong>Why not MCU:</strong> MCU decodes + re-encodes (CPU-intensive, adds latency). SFU just forwards packets — lower latency, horizontally scalable</li>
</ul>

<h3>Deep Dive: STUN/TURN</h3>
<ul>
<li><strong>STUN (Session Traversal Utilities for NAT):</strong> UDP-based, discovers public IP:port mapping. Works for ~80% of NAT types</li>
<li><strong>TURN (Traversal Using Relays around NAT):</strong> TCP/UDP relay for symmetric NAT cases (~20%). All media relayed through TURN server — adds latency but ensures connectivity</li>
<li><strong>ICE (Interactive Connectivity Establishment):</strong> Framework that tries STUN first, falls back to TURN</li>
</ul>
</div>

<!-- Flow 2: Real-time Media Streaming -->
<div class="section">
<h2>Flow 2: Real-time Audio/Video Streaming</h2>
<div class="diagram-container">
<svg viewBox="0 0 1050 420" xmlns="http://www.w3.org/2000/svg">
<defs><marker id="arrow2" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto"><polygon points="0 0, 10 3.5, 0 7" fill="#ffaa00"/></marker></defs>
<rect x="30" y="170" width="130" height="60" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="95" y="195" text-anchor="middle" fill="white" font-size="12">Sender Client</text><text x="95" y="212" text-anchor="middle" fill="white" font-size="11">(Camera+Mic)</text>
<rect x="220" y="50" width="140" height="50" rx="8" fill="#d4a017" stroke="#f0c040" stroke-width="2"/><text x="290" y="80" text-anchor="middle" fill="white" font-size="12">Codec Encoder</text>
<text x="290" y="120" text-anchor="middle" fill="#aaa" font-size="11">VP8/VP9/H.264 (video)</text>
<text x="290" y="135" text-anchor="middle" fill="#aaa" font-size="11">Opus (audio)</text>
<rect x="220" y="170" width="140" height="50" rx="8" fill="#c77dba" stroke="#e0a5d8" stroke-width="2"/><text x="290" y="195" text-anchor="middle" fill="white" font-size="12">Jitter Buffer</text><text x="290" y="212" text-anchor="middle" fill="white" font-size="11">+ NACK/FEC</text>
<rect x="220" y="290" width="140" height="50" rx="8" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="290" y="320" text-anchor="middle" fill="white" font-size="12">SRTP Packetizer</text>
<rect x="450" y="170" width="140" height="60" rx="10" fill="#1e6091" stroke="#3a8cbf" stroke-width="2"/><text x="520" y="195" text-anchor="middle" fill="white" font-size="13">SFU Media</text><text x="520" y="212" text-anchor="middle" fill="white" font-size="13">Server</text>
<rect x="680" y="80" width="130" height="50" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="745" y="110" text-anchor="middle" fill="white" font-size="12">Receiver A</text>
<rect x="680" y="170" width="130" height="50" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="745" y="200" text-anchor="middle" fill="white" font-size="12">Receiver B</text>
<rect x="680" y="260" width="130" height="50" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="745" y="290" text-anchor="middle" fill="white" font-size="12">Receiver C</text>
<rect x="680" y="350" width="130" height="50" rx="10" fill="#e76f51" stroke="#ff9a76" stroke-width="2"/><text x="745" y="375" text-anchor="middle" fill="white" font-size="11">Recording Svc</text><text x="745" y="390" text-anchor="middle" fill="white" font-size="10">(if enabled)</text>
<line x1="160" y1="185" x2="218" y2="80" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="160" y1="200" x2="218" y2="195" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="160" y1="215" x2="218" y2="310" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="360" y1="195" x2="448" y2="195" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="590" y1="180" x2="678" y2="105" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="590" y1="200" x2="678" y2="195" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="590" y1="220" x2="678" y2="280" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<line x1="590" y1="230" x2="678" y2="370" stroke="#ffaa00" stroke-width="2" marker-end="url(#arrow2)"/>
<text x="520" y="25" text-anchor="middle" fill="#aaa" font-size="16" font-weight="bold">Zoom: Real-time Media Streaming via SFU</text>
</svg>
</div>

<h3>Step-by-Step</h3>
<ol>
<li><strong>Capture:</strong> Camera captures frames at 30fps, mic captures audio at 48kHz</li>
<li><strong>Encode:</strong> VP9/H.264 encodes video with simulcast (3 spatial layers); Opus encodes audio</li>
<li><strong>Packetize:</strong> RTP packets wrapped in SRTP (encrypted). Each packet ~1200 bytes (fits in MTU)</li>
<li><strong>Transmit (UDP):</strong> SRTP packets sent over UDP to SFU. No TCP retransmission — speed over reliability</li>
<li><strong>SFU selects layer:</strong> For each receiver, SFU picks appropriate simulcast layer based on receiver's bandwidth estimate</li>
<li><strong>Forward:</strong> SFU forwards selected SRTP packets to each receiver (no transcoding)</li>
<li><strong>Receive + Decode:</strong> Receiver's jitter buffer reorders packets, decoder renders frames</li>
<li><strong>Recording (optional):</strong> SFU forks a copy of all streams to Recording Service → transcoded to MP4 → stored in S3</li>
</ol>

<div class="example">
<strong>Example:</strong> In a 5-person meeting, Alice sends her video at 3 quality layers (720p, 360p, 180p). SFU sends 720p to Bob (good WiFi), 360p to Charlie (4G), and 180p to Dave (poor connection). SFU only forwards — no CPU-intensive transcoding. Each participant uploads 1 stream, downloads 4 streams.
</div>

<h3>Deep Dive: UDP vs TCP for Media</h3>
<ul>
<li><strong>UDP chosen because:</strong> No head-of-line blocking. If a packet is lost, the video continues with a brief artifact rather than stalling. For real-time video, a slightly corrupted frame is better than a delayed one</li>
<li><strong>TCP would cause:</strong> Retransmission delays (100-300ms RTT penalty per lost packet), bufferbloat, and stalls — unacceptable for real-time communication</li>
<li><strong>Loss recovery:</strong> NACK (Negative Acknowledgment) requests retransmission of critical packets (e.g., keyframes). FEC (Forward Error Correction) adds redundant packets so receiver can reconstruct lost data without retransmission</li>
</ul>

<h3>Deep Dive: Simulcast + SVC</h3>
<ul>
<li><strong>Simulcast:</strong> Client encodes video at 3 resolutions simultaneously (e.g., 720p, 360p, 180p). SFU picks per-receiver</li>
<li><strong>SVC (Scalable Video Coding):</strong> Single encoded stream with temporal/spatial layers. SFU drops layers to reduce quality — more bandwidth efficient than simulcast but codec support is limited</li>
<li><strong>Bandwidth estimation:</strong> SFU uses REMB (Receiver Estimated Maximum Bitrate) and Transport-CC feedback to determine each receiver's available bandwidth in real-time</li>
</ul>
</div>

<!-- Flow 3: Screen Sharing -->
<div class="section">
<h2>Flow 3: Screen Sharing</h2>
<div class="diagram-container">
<svg viewBox="0 0 900 300" xmlns="http://www.w3.org/2000/svg">
<defs><marker id="arrow3" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto"><polygon points="0 0, 10 3.5, 0 7" fill="#66ff66"/></marker></defs>
<rect x="30" y="120" width="130" height="60" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="95" y="148" text-anchor="middle" fill="white" font-size="12">Sharer Client</text><text x="95" y="165" text-anchor="middle" fill="white" font-size="11">(Screen Capture)</text>
<rect x="220" y="120" width="140" height="60" rx="10" fill="#d4a017" stroke="#f0c040" stroke-width="2"/><text x="290" y="148" text-anchor="middle" fill="white" font-size="12">VP9 Encoder</text><text x="290" y="165" text-anchor="middle" fill="white" font-size="11">(Content Mode)</text>
<rect x="430" y="120" width="140" height="60" rx="10" fill="#1e6091" stroke="#3a8cbf" stroke-width="2"/><text x="500" y="155" text-anchor="middle" fill="white" font-size="13">SFU</text>
<rect x="640" y="60" width="130" height="50" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="705" y="90" text-anchor="middle" fill="white" font-size="12">Viewer A</text>
<rect x="640" y="150" width="130" height="50" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="705" y="180" text-anchor="middle" fill="white" font-size="12">Viewer B</text>
<rect x="640" y="240" width="130" height="50" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="705" y="270" text-anchor="middle" fill="white" font-size="12">Viewer C</text>
<line x1="160" y1="150" x2="218" y2="150" stroke="#66ff66" stroke-width="2" marker-end="url(#arrow3)"/>
<line x1="360" y1="150" x2="428" y2="150" stroke="#66ff66" stroke-width="2" marker-end="url(#arrow3)"/>
<line x1="570" y1="140" x2="638" y2="90" stroke="#66ff66" stroke-width="2" marker-end="url(#arrow3)"/>
<line x1="570" y1="150" x2="638" y2="175" stroke="#66ff66" stroke-width="2" marker-end="url(#arrow3)"/>
<line x1="570" y1="170" x2="638" y2="260" stroke="#66ff66" stroke-width="2" marker-end="url(#arrow3)"/>
<text x="450" y="25" text-anchor="middle" fill="#aaa" font-size="16" font-weight="bold">Zoom: Screen Sharing Flow</text>
</svg>
</div>
<ul>
<li><strong>Content mode encoding:</strong> VP9 with high-resolution, lower frame rate (5-15 fps), optimized for text/slides (sharper than video mode). Uses <code>content_hint: "detail"</code></li>
<li><strong>Separate stream:</strong> Screen share is a separate media track from camera — SFU treats it as an additional stream. Participants can pin or view gallery+screen simultaneously</li>
<li><strong>Annotation:</strong> Annotations are sent as overlay data via the signaling channel (DataChannel), not embedded in the video stream</li>
</ul>

<div class="example">
<strong>Example:</strong> Alice shares her screen while presenting slides. Encoder switches to content mode (high resolution 1080p, 10fps). VP9 is particularly efficient for screen content (large static areas compress well). Each viewer receives the high-res stream. Bob with slow connection gets a lower-resolution layer via simulcast.
</div>
</div>

<!-- Combined Flow -->
<div class="section">
<h2>Combined Overall Architecture</h2>
<div class="diagram-container">
<svg viewBox="0 0 1200 650" xmlns="http://www.w3.org/2000/svg">
<defs><marker id="arrow4" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto"><polygon points="0 0, 10 3.5, 0 7" fill="#00aaff"/></marker></defs>
<rect x="30" y="250" width="120" height="80" rx="10" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="90" y="283" text-anchor="middle" fill="white" font-size="12">Client Apps</text><text x="90" y="300" text-anchor="middle" fill="white" font-size="10">(Desktop/Mobile/</text><text x="90" y="315" text-anchor="middle" fill="white" font-size="10">Web)</text>
<rect x="200" y="200" width="130" height="50" rx="8" fill="#e76f51" stroke="#ff9a76" stroke-width="2"/><text x="265" y="230" text-anchor="middle" fill="white" font-size="12">API Gateway</text>
<rect x="200" y="310" width="130" height="50" rx="8" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="265" y="335" text-anchor="middle" fill="white" font-size="11">Signaling (WSS)</text><text x="265" y="350" text-anchor="middle" fill="white" font-size="10">SDP/ICE</text>
<rect x="400" y="80" width="140" height="50" rx="8" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="470" y="110" text-anchor="middle" fill="white" font-size="12">Meeting Service</text>
<rect x="400" y="170" width="140" height="50" rx="8" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="470" y="200" text-anchor="middle" fill="white" font-size="12">Auth Service</text>
<rect x="400" y="260" width="140" height="50" rx="8" fill="#457b9d" stroke="#6db5d9" stroke-width="2"/><text x="470" y="290" text-anchor="middle" fill="white" font-size="12">Chat Service</text>
<rect x="400" y="350" width="140" height="50" rx="8" fill="#8338ec" stroke="#b06efd" stroke-width="2"/><text x="470" y="380" text-anchor="middle" fill="white" font-size="12">SFU Router</text>
<rect x="640" y="100" width="140" height="50" rx="8" fill="#1e6091" stroke="#3a8cbf" stroke-width="2"/><text x="710" y="125" text-anchor="middle" fill="white" font-size="11">Media Server (SFU)</text><text x="710" y="140" text-anchor="middle" fill="white" font-size="10">us-east-1</text>
<rect x="640" y="190" width="140" height="50" rx="8" fill="#1e6091" stroke="#3a8cbf" stroke-width="2"/><text x="710" y="215" text-anchor="middle" fill="white" font-size="11">Media Server (SFU)</text><text x="710" y="230" text-anchor="middle" fill="white" font-size="10">eu-west-1</text>
<rect x="640" y="280" width="140" height="50" rx="8" fill="#1e6091" stroke="#3a8cbf" stroke-width="2"/><text x="710" y="305" text-anchor="middle" fill="white" font-size="11">Media Server (SFU)</text><text x="710" y="320" text-anchor="middle" fill="white" font-size="10">ap-southeast-1</text>
<rect x="640" y="380" width="130" height="50" rx="8" fill="#c77dba" stroke="#e0a5d8" stroke-width="2"/><text x="705" y="410" text-anchor="middle" fill="white" font-size="12">TURN/STUN</text>
<rect x="880" y="100" width="140" height="50" rx="8" fill="#e76f51" stroke="#ff9a76" stroke-width="2"/><text x="950" y="125" text-anchor="middle" fill="white" font-size="11">Recording Service</text><text x="950" y="140" text-anchor="middle" fill="white" font-size="10">→ S3</text>
<rect x="880" y="190" width="140" height="50" rx="8" fill="#d4a017" stroke="#f0c040" stroke-width="2"/><text x="950" y="215" text-anchor="middle" fill="white" font-size="11">Transcription Svc</text><text x="950" y="230" text-anchor="middle" fill="white" font-size="10">(AI/ML)</text>
<ellipse cx="950" cy="320" rx="70" ry="30" fill="#6b2fa0" stroke="#9d5fd0" stroke-width="2"/><text x="950" y="325" text-anchor="middle" fill="white" font-size="12">Meeting DB</text>
<ellipse cx="950" cy="410" rx="70" ry="30" fill="#6b2fa0" stroke="#9d5fd0" stroke-width="2"/><text x="950" y="415" text-anchor="middle" fill="white" font-size="12">Chat DB</text>
<rect x="400" y="470" width="140" height="50" rx="8" fill="#2a9d8f" stroke="#4ad4c0" stroke-width="2"/><text x="470" y="500" text-anchor="middle" fill="white" font-size="12">Waiting Room Svc</text>
<rect x="640" y="470" width="140" height="50" rx="8" fill="#d4a017" stroke="#f0c040" stroke-width="2"/><text x="710" y="500" text-anchor="middle" fill="white" font-size="12">Notification Svc</text>
<line x1="150" y1="275" x2="198" y2="230" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow4)"/>
<line x1="150" y1="305" x2="198" y2="335" stroke="#00aaff" stroke-width="2" marker-end="url(#arrow4)"/>
<line x1="330" y1="215" x2="398" y2="105" stroke="#00aaff" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="330" y1="225" x2="398" y2="195" stroke="#00aaff" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="330" y1="340" x2="398" y2="285" stroke="#00aaff" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="330" y1="345" x2="398" y2="375" stroke="#00aaff" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="540" y1="375" x2="638" y2="130" stroke="#ffaa00" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="540" y1="375" x2="638" y2="215" stroke="#ffaa00" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="540" y1="375" x2="638" y2="300" stroke="#ffaa00" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="540" y1="385" x2="638" y2="405" stroke="#ffaa00" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="780" y1="120" x2="878" y2="120" stroke="#ff6b6b" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="780" y1="135" x2="878" y2="210" stroke="#ff6b6b" stroke-width="1.5" marker-end="url(#arrow4)"/>
<line x1="540" y1="105" x2="878" y2="310" stroke="#ff6b6b" stroke-width="1" stroke-dasharray="5,5" marker-end="url(#arrow4)"/>
<line x1="540" y1="285" x2="878" y2="400" stroke="#ff6b6b" stroke-width="1" stroke-dasharray="5,5" marker-end="url(#arrow4)"/>
<text x="600" y="25" text-anchor="middle" fill="#aaa" font-size="16" font-weight="bold">Zoom: Combined Overall Architecture</text>
</svg>
</div>

<div class="example">
<strong>Example — Full meeting lifecycle:</strong> Alice creates meeting → Meeting Service generates ID, stores in DB → Alice joins via WebSocket signaling → SFU Router assigns us-east-1 SFU → Bob (in Europe) joins → SFU Router assigns eu-west-1 SFU → Two SFUs cascade (forward streams between regions) → Charlie shares screen → separate screen share stream flows through SFU → Recording enabled → SFU forks all streams to Recording Service → After meeting, recording transcoded to MP4 → stored in S3 → Transcription Service generates captions from audio → Chat messages persisted to Chat DB.
</div>
</div>

<!-- Database Schema -->
<div class="section">
<h2>Database Schema</h2>

<h3>SQL — PostgreSQL (Users, Accounts, Meeting Config)</h3>
<table>
<tr><th>Table</th><th>Column</th><th>Type</th><th>Details</th></tr>
<tr><td rowspan="6"><strong>users</strong></td><td>user_id</td><td>BIGINT</td><td><span class="tag tag-pk">PK</span></td></tr>
<tr><td>email</td><td>VARCHAR(255)</td><td><span class="tag tag-idx">UNIQUE INDEX</span></td></tr>
<tr><td>display_name</td><td>VARCHAR(100)</td><td></td></tr>
<tr><td>password_hash</td><td>VARCHAR(255)</td><td></td></tr>
<tr><td>plan_type</td><td>ENUM(free,pro,business,enterprise)</td><td></td></tr>
<tr><td>created_at</td><td>TIMESTAMP</td><td></td></tr>
<tr><td rowspan="8"><strong>meetings</strong></td><td>meeting_id</td><td>BIGINT</td><td><span class="tag tag-pk">PK</span> (11-digit numeric)</td></tr>
<tr><td>host_user_id</td><td>BIGINT</td><td><span class="tag tag-fk">FK → users</span> <span class="tag tag-idx">INDEX</span></td></tr>
<tr><td>title</td><td>VARCHAR(255)</td><td></td></tr>
<tr><td>passcode</td><td>VARCHAR(10)</td><td></td></tr>
<tr><td>scheduled_start</td><td>TIMESTAMP</td><td><span class="tag tag-idx">INDEX</span></td></tr>
<tr><td>duration_minutes</td><td>INT</td><td></td></tr>
<tr><td>is_recurring</td><td>BOOLEAN</td><td></td></tr>
<tr><td>settings</td><td>JSONB</td><td>waiting_room, e2ee, recording, etc.</td></tr>
</table>

<h4>Sharding Strategy (SQL)</h4>
<ul>
<li><strong>users:</strong> Shard by <code>user_id</code> (hash-based). Users are the primary access pattern for login/profile</li>
<li><strong>meetings:</strong> Shard by <code>meeting_id</code> (hash-based). Join operations look up by meeting_id, so this is the primary key</li>
<li>Cross-shard query for "my meetings" uses <code>host_user_id</code> index → scatter-gather across shards (acceptable since it's a read-only dashboard query)</li>
</ul>

<h3>NoSQL — Cassandra (Chat Messages, Participants, Recordings)</h3>
<table>
<tr><th>Table</th><th>Column</th><th>Type</th><th>Details</th></tr>
<tr><td rowspan="5"><strong>chat_messages</strong></td><td>meeting_id</td><td>BIGINT</td><td><span class="tag tag-pk">Partition Key</span></td></tr>
<tr><td>message_id</td><td>TIMEUUID</td><td><span class="tag tag-pk">Clustering Key</span> (ASC)</td></tr>
<tr><td>sender_user_id</td><td>BIGINT</td><td></td></tr>
<tr><td>content</td><td>TEXT</td><td></td></tr>
<tr><td>message_type</td><td>TEXT</td><td>text, file, reaction</td></tr>
<tr><td rowspan="5"><strong>meeting_participants</strong></td><td>meeting_id</td><td>BIGINT</td><td><span class="tag tag-pk">Partition Key</span></td></tr>
<tr><td>user_id</td><td>BIGINT</td><td><span class="tag tag-pk">Clustering Key</span></td></tr>
<tr><td>join_time</td><td>TIMESTAMP</td><td></td></tr>
<tr><td>leave_time</td><td>TIMESTAMP</td><td></td></tr>
<tr><td>role</td><td>TEXT</td><td>host, co-host, participant</td></tr>
<tr><td rowspan="5"><strong>recordings</strong></td><td>meeting_id</td><td>BIGINT</td><td><span class="tag tag-pk">Partition Key</span></td></tr>
<tr><td>recording_id</td><td>TIMEUUID</td><td><span class="tag tag-pk">Clustering Key</span></td></tr>
<tr><td>s3_url</td><td>TEXT</td><td></td></tr>
<tr><td>duration_seconds</td><td>INT</td><td></td></tr>
<tr><td>status</td><td>TEXT</td><td>processing, ready, expired</td></tr>
</table>

<h4>Why Cassandra for Chat/Participants?</h4>
<ul>
<li>Chat messages are write-heavy, append-only, and read by meeting_id (partition key = meeting_id ensures all messages for a meeting are co-located)</li>
<li>meeting_participants is read when displaying participant list — bounded per meeting (&lt;1000 rows per partition)</li>
<li>Cassandra handles the write throughput of millions of concurrent meetings sending chat messages</li>
</ul>

<h3>Denormalization</h3>
<ul>
<li><strong>Active participant count</strong> denormalized in Redis: <code>meeting:{meeting_id}:count</code> — INCR on join, DECR on leave. Avoids counting rows in Cassandra</li>
<li><strong>Meeting status</strong> (waiting, in-progress, ended) stored in both PostgreSQL (authoritative) and Redis (fast lookup for join flow)</li>
</ul>

<h3>Indexes Explanation</h3>
<ul>
<li><code>meetings.host_user_id</code> — B-tree index for "list my meetings" dashboard query</li>
<li><code>meetings.scheduled_start</code> — B-tree index for upcoming meeting reminders and cleanup jobs</li>
<li><code>users.email</code> — Unique B-tree index for login lookups (email → user_id)</li>
</ul>
</div>

<!-- Cache Deep Dive -->
<div class="section">
<h2>Cache Deep Dive</h2>
<h3>Redis Cache Layers</h3>
<table>
<tr><th>Cache</th><th>Key Pattern</th><th>Value</th><th>TTL</th><th>Strategy</th></tr>
<tr><td>Meeting State</td><td><code>meeting:{id}:state</code></td><td>JSON (participants, settings, status)</td><td>Duration of meeting + 1hr</td><td>Write-through</td></tr>
<tr><td>SFU Assignment</td><td><code>meeting:{id}:sfu</code></td><td>SFU server address</td><td>Duration of meeting</td><td>Write-through</td></tr>
<tr><td>Auth Token</td><td><code>session:{token}</code></td><td>user_id, permissions</td><td>24 hours</td><td>Write-through</td></tr>
<tr><td>Active Count</td><td><code>meeting:{id}:count</code></td><td>Integer</td><td>Duration of meeting</td><td>Atomic INCR/DECR</td></tr>
</table>

<h3>Eviction Policy</h3>
<ul>
<li><strong>Policy:</strong> <code>volatile-ttl</code> — evict keys with nearest expiry first. Meeting caches naturally expire when meetings end</li>
<li><strong>No CDN needed</strong> for real-time media (it's live, not cacheable). CDN used only for static assets (JS/CSS, recording playback)</li>
</ul>

<h3>CDN Usage</h3>
<ul>
<li><strong>Static assets:</strong> Web client JS bundle, mobile app assets served via CDN</li>
<li><strong>Recording playback:</strong> Completed recordings in S3 served via CloudFront CDN with signed URLs (time-limited access)</li>
<li><strong>Strategy:</strong> Pull-based CDN — first request pulls from S3 origin, subsequent requests served from edge cache</li>
<li><strong>TTL:</strong> 7 days for recordings, 30 days for static assets</li>
</ul>
</div>

<!-- Scaling -->
<div class="section">
<h2>Scaling Considerations</h2>
<ul>
<li><strong>Signaling servers:</strong> Stateless, horizontally scalable behind L4 load balancer. WebSocket sessions use sticky sessions (IP hash)</li>
<li><strong>SFU scaling:</strong> Each SFU handles ~100-500 participants depending on hardware. For large meetings (>300), cascade multiple SFUs (SFU-to-SFU forwarding)</li>
<li><strong>Geographic distribution:</strong> SFU clusters in every major region. SFU Router picks closest cluster. For cross-region meetings, SFUs cascade with dedicated inter-DC links (lower latency than public internet)</li>
<li><strong>Recording Service:</strong> Scales independently. Uses Kafka queue — SFU publishes "record stream X" events, Recording workers consume and process. Can scale workers based on queue depth</li>
<li><strong>Load balancing:</strong> L4 (TCP/UDP) for media traffic to SFUs; L7 (HTTP) for REST APIs. Consistent hashing ensures meeting participants land on the same SFU</li>
<li><strong>Auto-scaling:</strong> SFU fleet auto-scales based on concurrent participant count. Pre-warms capacity before known peak times (9am Monday, school hours)</li>
</ul>
</div>

<!-- Tradeoffs -->
<div class="section">
<h2>Tradeoffs & Deep Dives</h2>
<div class="tradeoff">
<div class="pro"><h4>✅ SFU Architecture</h4><ul><li>O(N) bandwidth per participant (vs O(N²) mesh)</li><li>No transcoding = low latency</li><li>Simulcast enables per-receiver quality adaptation</li><li>Horizontally scalable</li></ul></div>
<div class="con"><h4>❌ SFU Downsides</h4><ul><li>Server bandwidth cost: each stream multiplied N times</li><li>SFU is stateful (participant sessions) — harder to migrate</li><li>Cascading SFUs for large meetings adds complexity</li></ul></div>
</div>
<div class="tradeoff">
<div class="pro"><h4>✅ WebRTC + UDP</h4><ul><li>Sub-100ms latency possible</li><li>Built-in encryption (DTLS-SRTP)</li><li>Adaptive bitrate via REMB/Transport-CC</li></ul></div>
<div class="con"><h4>❌ WebRTC Challenges</h4><ul><li>NAT traversal complexity (need STUN/TURN infrastructure)</li><li>UDP blocked on some corporate networks → need TCP fallback</li><li>Browser implementation inconsistencies</li></ul></div>
</div>

<h3>WebSocket Deep Dive (Signaling)</h3>
<ul>
<li><strong>Why WebSocket for signaling:</strong> Persistent connection for real-time SDP/ICE exchange. HTTP polling would add unacceptable latency to the join flow</li>
<li><strong>Message types:</strong> join, leave, offer, answer, ice-candidate, mute, unmute, screen-share-start, screen-share-stop, chat, reaction</li>
<li><strong>Heartbeat:</strong> Ping/pong every 10 seconds to detect disconnected clients</li>
</ul>
</div>

<!-- Alternative Approaches -->
<div class="section">
<h2>Alternative Approaches</h2>
<ul>
<li><strong>MCU (Multipoint Control Unit):</strong> Server decodes all streams, composites into one mixed stream, re-encodes and sends to each participant. Pros: clients receive only 1 stream (low bandwidth). Cons: Very high server CPU, added latency (encode+decode), no individual video layout control. Used in older systems</li>
<li><strong>Mesh (P2P):</strong> Every participant connects directly to every other. Pros: No server infrastructure for media. Cons: O(N²) connections, doesn't scale beyond 4-5 participants, NAT traversal needed for every pair</li>
<li><strong>HLS/DASH for large events:</strong> For webinars with >10K viewers, switch to one-way HLS streaming (5-30s latency acceptable for view-only). Reduces SFU load dramatically</li>
<li><strong>E2EE implementation:</strong> Insertable Streams API (WebRTC) — encrypt media frames before they reach the SFU. SFU can still route packets (encrypted) but cannot see content. Tradeoff: server-side recording and transcription become impossible</li>
</ul>
</div>

<!-- Additional Info -->
<div class="section">
<h2>Additional Information</h2>
<ul>
<li><strong>Breakout rooms:</strong> Logically separate sub-meetings on the same SFU (or different SFU). Signaling server manages room-to-SFU mapping. Moving between rooms = SDP renegotiation</li>
<li><strong>Virtual backgrounds:</strong> Client-side ML model (MediaPipe / TensorFlow Lite) segments person from background at ~30fps. Processed before encoding — SFU sees normal video</li>
<li><strong>Noise suppression:</strong> Client-side RNNoise or proprietary ML model processes audio before encoding. Removes keyboard clicks, dog barks, etc.</li>
<li><strong>End-to-end latency budget:</strong> Capture (5ms) + Encode (10ms) + Network (30-80ms) + SFU routing (1ms) + Jitter buffer (20-40ms) + Decode (10ms) + Render (5ms) = ~80-150ms total</li>
<li><strong>Bandwidth usage:</strong> ~1.5 Mbps per 720p video stream. 10-person meeting: ~15 Mbps download for gallery view</li>
</ul>
</div>
</body>
</html>
