<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>System Design: Figma</title>
<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<style>
  :root {
    --bg: #0f1117;
    --surface: #1a1d27;
    --surface2: #232733;
    --border: #2e3346;
    --text: #e1e4ed;
    --text-dim: #9498a8;
    --accent: #6c5ce7;
    --accent2: #a29bfe;
    --green: #00cec9;
    --orange: #fdcb6e;
    --red: #ff7675;
    --blue: #74b9ff;
  }
  * { margin: 0; padding: 0; box-sizing: border-box; }
  body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background: var(--bg);
    color: var(--text);
    line-height: 1.7;
    padding: 2rem;
    max-width: 1200px;
    margin: 0 auto;
  }
  h1 {
    font-size: 2.8rem;
    font-weight: 800;
    background: linear-gradient(135deg, var(--accent), var(--accent2), var(--blue));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 0.5rem;
  }
  .subtitle {
    color: var(--text-dim);
    font-size: 1.15rem;
    margin-bottom: 3rem;
    border-bottom: 1px solid var(--border);
    padding-bottom: 1.5rem;
  }
  h2 {
    font-size: 1.8rem;
    font-weight: 700;
    color: var(--accent2);
    margin-top: 3rem;
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid var(--accent);
  }
  h3 {
    font-size: 1.35rem;
    font-weight: 600;
    color: var(--blue);
    margin-top: 2rem;
    margin-bottom: 0.75rem;
  }
  h4 {
    font-size: 1.1rem;
    font-weight: 600;
    color: var(--green);
    margin-top: 1.5rem;
    margin-bottom: 0.5rem;
  }
  p { margin-bottom: 1rem; }
  ul, ol {
    margin-bottom: 1rem;
    padding-left: 1.5rem;
  }
  li { margin-bottom: 0.4rem; }
  .card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 1.5rem;
    margin-bottom: 1.5rem;
  }
  .example-card {
    background: var(--surface2);
    border-left: 4px solid var(--green);
    border-radius: 0 8px 8px 0;
    padding: 1.25rem 1.5rem;
    margin-bottom: 1rem;
  }
  .example-card strong { color: var(--green); }
  .warn-card {
    background: var(--surface2);
    border-left: 4px solid var(--orange);
    border-radius: 0 8px 8px 0;
    padding: 1.25rem 1.5rem;
    margin-bottom: 1rem;
  }
  .warn-card strong { color: var(--orange); }
  .diagram-container {
    background: #ffffff;
    border-radius: 12px;
    padding: 1.5rem;
    margin: 1.5rem 0;
    overflow-x: auto;
  }
  table {
    width: 100%;
    border-collapse: collapse;
    margin-bottom: 1.5rem;
    background: var(--surface);
    border-radius: 8px;
    overflow: hidden;
  }
  th {
    background: var(--surface2);
    color: var(--accent2);
    font-weight: 600;
    text-align: left;
    padding: 0.75rem 1rem;
    border-bottom: 2px solid var(--border);
  }
  td {
    padding: 0.65rem 1rem;
    border-bottom: 1px solid var(--border);
  }
  code {
    background: var(--surface2);
    padding: 0.15rem 0.4rem;
    border-radius: 4px;
    font-family: 'JetBrains Mono', 'Fira Code', monospace;
    font-size: 0.9rem;
    color: var(--orange);
  }
  .tag {
    display: inline-block;
    padding: 0.15rem 0.6rem;
    border-radius: 12px;
    font-size: 0.8rem;
    font-weight: 600;
  }
  .tag-pk { background: #6c5ce733; color: var(--accent2); }
  .tag-fk { background: #74b9ff33; color: var(--blue); }
  .tag-idx { background: #00cec933; color: var(--green); }
  .tag-shard { background: #fdcb6e33; color: var(--orange); }
  .toc {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 12px;
    padding: 1.5rem 2rem;
    margin-bottom: 2rem;
  }
  .toc a {
    color: var(--accent2);
    text-decoration: none;
    transition: color 0.2s;
  }
  .toc a:hover { color: var(--blue); }
  .toc ul { list-style: none; padding-left: 1rem; }
  .toc > ul { padding-left: 0; }
</style>
</head>
<body>

<h1>System Design: Figma</h1>
<p class="subtitle">A real-time collaborative design tool ‚Äî enabling multiple designers to simultaneously create, edit, and prototype vector-based interfaces in the browser.</p>

<!-- TABLE OF CONTENTS -->
<div class="toc">
  <h3 style="margin-top:0;">Table of Contents</h3>
  <ul>
    <li><a href="#fr">1. Functional Requirements</a></li>
    <li><a href="#nfr">2. Non-Functional Requirements</a></li>
    <li><a href="#flow1">3. Flow 1 ‚Äî File Open &amp; Real-Time Collaborative Editing</a></li>
    <li><a href="#flow2">4. Flow 2 ‚Äî Commenting &amp; Notification</a></li>
    <li><a href="#flow3">5. Flow 3 ‚Äî Version History</a></li>
    <li><a href="#flow4">6. Flow 4 ‚Äî File Sharing &amp; Permissions</a></li>
    <li><a href="#flow5">7. Flow 5 ‚Äî Asset Upload &amp; Export</a></li>
    <li><a href="#overall">8. Overall Combined Diagram</a></li>
    <li><a href="#schema">9. Database Schema</a></li>
    <li><a href="#cdn-cache">10. CDN &amp; Caching Deep Dive</a></li>
    <li><a href="#websocket">11. WebSocket Deep Dive</a></li>
    <li><a href="#crdt">12. CRDT / Conflict Resolution Deep Dive</a></li>
    <li><a href="#pubsub">13. Pub/Sub Deep Dive</a></li>
    <li><a href="#lb">14. Load Balancers</a></li>
    <li><a href="#scaling">15. Scaling Considerations</a></li>
    <li><a href="#tradeoffs">16. Tradeoffs &amp; Deep Dives</a></li>
    <li><a href="#alternatives">17. Alternative Approaches</a></li>
    <li><a href="#additional">18. Additional Information</a></li>
    <li><a href="#vendors">19. Vendor Section</a></li>
  </ul>
</div>

<!-- ========================== FUNCTIONAL REQUIREMENTS ========================== -->
<h2 id="fr">1. Functional Requirements</h2>
<div class="card">
<ol>
  <li><strong>Design File Editing:</strong> Users can create, open, and edit vector-based design files containing shapes, text, images, paths, boolean operations, masks, and groups on an infinite canvas.</li>
  <li><strong>Real-Time Collaboration:</strong> Multiple users can simultaneously edit the same design file and see each other's cursors, selections, and changes in real time (&lt;200ms propagation).</li>
  <li><strong>Presence Awareness:</strong> Users can see who else is viewing/editing the file, which page they are on, and their cursor positions.</li>
  <li><strong>Component &amp; Design System:</strong> Users can create reusable components with overridable properties. Instances of components update when the main component changes.</li>
  <li><strong>Prototyping:</strong> Users can wire up interactive prototypes with transitions, overlays, and scroll behaviors, then preview them.</li>
  <li><strong>Commenting:</strong> Users can pin comments to specific locations on the canvas, reply in threads, resolve comments, and tag other users.</li>
  <li><strong>Version History:</strong> The system automatically saves snapshots at intervals and on meaningful milestones. Users can browse, preview, name, and restore previous versions.</li>
  <li><strong>File &amp; Project Organization:</strong> Files are organized into projects, which belong to teams. Users can search, move, star, and archive files.</li>
  <li><strong>Sharing &amp; Permissions:</strong> File owners can share files with view-only, edit, or owner permissions via link or email invitation. Team-level permissions also exist.</li>
  <li><strong>Asset Upload:</strong> Users can upload raster images (PNG, JPG, GIF) and SVGs which are embedded into the design.</li>
  <li><strong>Export:</strong> Users can export frames, components, or entire pages as PNG, SVG, PDF, or JPG at configurable scales.</li>
  <li><strong>Notifications:</strong> Users receive notifications when they are mentioned in comments, when files are shared with them, or when watched files change.</li>
</ol>
</div>

<!-- ========================== NON-FUNCTIONAL REQUIREMENTS ========================== -->
<h2 id="nfr">2. Non-Functional Requirements</h2>
<div class="card">
<ol>
  <li><strong>Low Latency:</strong> Cursor/presence updates propagated in &lt;50ms. Design operations propagated in &lt;200ms to all collaborators.</li>
  <li><strong>Consistency:</strong> All collaborators must converge to the same document state (strong eventual consistency via CRDT). No data loss on concurrent edits.</li>
  <li><strong>High Availability:</strong> 99.9% uptime. Editing should not be blocked by backend unavailability ‚Äî local buffering with reconciliation.</li>
  <li><strong>Scalability:</strong> Support 10M+ design files, 1M+ concurrent users, and files with 100K+ objects. Support up to ~50 simultaneous editors per file.</li>
  <li><strong>Durability:</strong> Zero data loss. All operations are durably persisted. Version history retained indefinitely for paid plans.</li>
  <li><strong>Performance:</strong> File open time &lt;3s for files under 50MB. Canvas rendering at 60fps via WebGL on the client.</li>
  <li><strong>Cross-Platform:</strong> Works in modern web browsers (Chrome, Firefox, Safari, Edge). Desktop app wraps the web experience.</li>
  <li><strong>Security:</strong> End-to-end access control enforcement. All API calls authenticated. WebSocket connections authenticated with tokens.</li>
  <li><strong>Bandwidth Efficiency:</strong> Only deltas (operations) are sent over the wire, not full file state. Binary encoding to minimize payload size.</li>
</ol>
</div>

<!-- ========================== FLOW 1 ========================== -->
<h2 id="flow1">3. Flow 1 ‚Äî File Open &amp; Real-Time Collaborative Editing</h2>
<p>This is the <strong>core flow</strong> of Figma. A user opens a design file, the file data is loaded, a WebSocket connection is established for real-time collaboration, and edits are synchronized across all connected clients via a CRDT-based conflict resolution system.</p>

<div class="diagram-container">
<pre class="mermaid">
flowchart LR
    subgraph Clients
        A["üë§ Client A<br/>(Browser/WebGL)"]
        B["üë§ Client B<br/>(Browser/WebGL)"]
    end

    LB["‚öñÔ∏è Load Balancer"]
    API["üîÄ API Gateway"]
    AUTH["üîê Auth Service"]

    subgraph Collaboration
        CS["üîÑ Collaboration<br/>Service<br/>(WebSocket Server)"]
        PS[("üì° Pub/Sub")]
        CS2["üîÑ Collaboration<br/>Service<br/>(Instance 2)"]
    end

    FS["üìÅ File Service"]
    CACHE[("üíæ In-Memory<br/>Cache")]
    DOCDB[("üìÑ Document DB<br/>(File Data)")]
    OPLOG[("üìù Operations Log<br/>(NoSQL)")]
    OBJ[("üóÇÔ∏è Object Storage<br/>(Assets)")]
    CDN["üåê CDN"]

    A -- "1 HTTP GET<br/>/files/:id" --> LB
    LB --> API
    API -- "2 Verify token" --> AUTH
    API -- "3 Load file data" --> FS
    FS -- "3a Cache hit?" --> CACHE
    FS -- "3b Cache miss" --> DOCDB
    FS -- "3c Asset URLs" --> CDN
    CDN -- "3d Origin" --> OBJ
    API -- "4 File data<br/>response" --> A

    A -- "5 WSS connect<br/>/collab/:fileId" --> LB
    LB -- "Sticky session" --> CS
    A -- "6 Send ops" --> CS
    CS -- "7 Persist ops" --> OPLOG
    CS -- "8 Broadcast" --> PS
    PS -- "9 Relay" --> CS2
    CS2 -- "10 Push ops" --> B
    CS -- "10 Push ops<br/>(same instance)" --> B
    B -- "6 Send ops" --> CS2
</pre>
</div>

<h3>Examples</h3>

<div class="example-card">
<strong>Example 1 ‚Äî Basic Collaborative Editing (Same Server Instance):</strong><br/>
Designer Alice opens <code>homepage-v3.fig</code> by navigating to <code>figma.com/file/abc123</code>. Her browser sends an <code>HTTP GET /api/files/abc123</code> through the Load Balancer ‚Üí API Gateway ‚Üí Auth Service (verifies her JWT) ‚Üí File Service. The File Service checks the in-memory cache for the file data. It's a cache miss, so it reads from the Document DB and returns the full file tree (a JSON/binary document describing every node ‚Äî frames, rectangles, text layers, etc.). Asset URLs (e.g., uploaded images) are resolved via the CDN. Alice's browser receives the file data, builds the local scene graph, and renders via WebGL. Her browser then opens a WebSocket connection to <code>wss://collab.figma.com/collab/abc123</code>. The Load Balancer routes her to Collaboration Service Instance 1 using sticky sessions (hashed by file ID). Bob, her teammate, is already connected to the same instance for this file. Alice drags a rectangle to a new position. Her client generates an operation: <code>{op: "update", nodeId: "rect_42", props: {x: 200, y: 150}, clock: 47}</code>. This operation is sent over the WebSocket to the Collaboration Service, which persists it to the Operations Log, merges it with the authoritative CRDT state, and broadcasts it directly to Bob (same instance). Bob's client receives and applies the operation, moving the rectangle on his screen within ~100ms.
</div>

<div class="example-card">
<strong>Example 2 ‚Äî Collaborative Editing (Cross-Server via Pub/Sub):</strong><br/>
Continuing the above scenario, a third designer Carol joins the file. The Load Balancer routes her WebSocket to Collaboration Service Instance 2 (Instance 1 has reached its connection threshold). Carol makes a change ‚Äî she updates the fill color of a button. Her operation is sent to Instance 2, which persists it to the Operations Log, then publishes it to the Pub/Sub channel <code>file:abc123</code>. Instance 1 is subscribed to this channel, receives the operation, and pushes it to both Alice and Bob. Meanwhile, if Alice makes a change, Instance 1 publishes to the same Pub/Sub channel, and Instance 2 relays it to Carol.
</div>

<div class="example-card">
<strong>Example 3 ‚Äî Conflict Resolution:</strong><br/>
Alice and Bob simultaneously move the same rectangle. Alice moves it to <code>(200, 300)</code> and Bob moves it to <code>(400, 100)</code>. Both operations arrive at the Collaboration Service within milliseconds. The server uses a Last-Writer-Wins (LWW) strategy based on logical timestamps (Lamport clocks). Bob's operation has a higher timestamp (it was processed second), so the rectangle ends up at <code>(400, 100)</code>. Both clients converge to this state. Alice sees her rectangle "jump" to Bob's position. This is acceptable because property-level conflicts on the same node are rare in practice ‚Äî designers typically work on different parts of the canvas.
</div>

<div class="example-card">
<strong>Example 4 ‚Äî Temporary Disconnection and Reconnection:</strong><br/>
Alice's WiFi drops for 15 seconds. During this time, she continues editing locally ‚Äî her operations are buffered in the client. When the WebSocket reconnects, the client sends a reconnection message including its last known server sequence number. The Collaboration Service replays any operations Alice missed (fetched from the Operations Log) and then processes Alice's buffered operations. Both sides converge without data loss.
</div>

<h3>Component Deep Dive ‚Äî Flow 1</h3>

<h4>Load Balancer</h4>
<p>Sits in front of both the API Gateway and the Collaboration Service. For HTTP requests, it performs round-robin or least-connections routing. For WebSocket connections, it uses <strong>sticky sessions</strong> hashed by <code>fileId</code> so that all collaborators of the same file are preferentially routed to the same Collaboration Service instance (reducing pub/sub hops). Operates at Layer 7 (application layer) to inspect the upgrade headers for WebSocket connections.</p>

<h4>API Gateway</h4>
<p>The entry point for all HTTP requests. Handles authentication (JWT verification via Auth Service), rate limiting, and request routing. Routes requests to the appropriate microservice.</p>
<ul>
  <li><strong>Protocol:</strong> HTTPS</li>
  <li><code>GET /api/files/:fileId</code> ‚Üí Returns file metadata and full file data (node tree). Input: <code>fileId</code> (path param), auth token (header). Output: <code>{ metadata: {...}, nodeTree: {...}, assetUrls: [...] }</code></li>
</ul>

<h4>Auth Service</h4>
<p>Validates JWT tokens, checks user permissions against the file's ACL. Called by the API Gateway on every HTTP request and by the Collaboration Service when a WebSocket connection is initiated.</p>
<ul>
  <li><strong>Protocol:</strong> Internal gRPC</li>
  <li>Input: JWT token, resource ID, required permission level. Output: <code>{ authorized: bool, userId: string }</code></li>
</ul>

<h4>File Service</h4>
<p>Manages file CRUD operations and file data retrieval. On a file open, it loads the file's node tree (either from cache or the Document DB). It also handles file creation, duplication, and deletion.</p>
<ul>
  <li><strong>Protocol:</strong> Internal gRPC (called by API Gateway)</li>
  <li><code>GetFile(fileId)</code> ‚Üí Returns the complete file data (node tree + metadata)</li>
  <li><code>CreateFile(name, projectId)</code> ‚Üí Creates a new empty file</li>
  <li><code>DeleteFile(fileId)</code> ‚Üí Soft-deletes a file</li>
</ul>

<h4>Collaboration Service (WebSocket Server)</h4>
<p>The heart of real-time collaboration. Manages WebSocket connections, maintains in-memory CRDT state for active files, processes incoming operations, persists them, and broadcasts them.</p>
<ul>
  <li><strong>Protocol:</strong> WSS (WebSocket Secure) ‚Äî persistent bidirectional connection</li>
  <li><strong>Connection establishment:</strong> Client sends <code>wss://collab.figma.com/collab/:fileId</code> with auth token in the initial handshake. The service verifies the token, loads the file's CRDT state into memory (if not already loaded), adds the client to the file's connection list, and begins relaying.</li>
  <li><strong>Inbound message types:</strong> <code>operation</code> (design change), <code>cursor_update</code> (mouse position), <code>selection_update</code> (selected nodes), <code>page_change</code> (which page the user is viewing).</li>
  <li><strong>Outbound message types:</strong> <code>operation</code>, <code>cursor_update</code>, <code>selection_update</code>, <code>presence_update</code> (who joined/left).</li>
  <li><strong>Connection registry:</strong> An in-memory hash map: <code>fileId ‚Üí Set&lt;{userId, socketRef, cursorPos, currentPage}&gt;</code></li>
</ul>

<h4>Pub/Sub</h4>
<p>Used for cross-instance communication when collaborators on the same file are connected to different Collaboration Service instances. Each Collaboration Service instance subscribes to a channel per active file it hosts. When an operation arrives, it is published to the channel so other instances can relay it.</p>
<ul>
  <li><strong>Channel pattern:</strong> <code>file:{fileId}</code></li>
  <li><strong>Message format:</strong> Serialized operation with metadata (userId, timestamp, sequenceNumber)</li>
</ul>

<h4>Document DB (File Data Store)</h4>
<p>Stores the <strong>materialized/compacted</strong> state of each design file as a document. This is the "snapshot" of the file ‚Äî the full node tree. Updated periodically by the Collaboration Service when it compacts the operations log into a new snapshot.</p>
<ul>
  <li><strong>Type:</strong> Document NoSQL database</li>
  <li><strong>Key:</strong> <code>fileId</code></li>
  <li><strong>Value:</strong> Binary-encoded node tree + metadata</li>
</ul>

<h4>Operations Log</h4>
<p>An append-only log of every operation applied to every file. Used for durability (crash recovery), reconnection replay, and building version history. Operations are never deleted ‚Äî they are compacted into snapshots after a threshold.</p>
<ul>
  <li><strong>Type:</strong> NoSQL (wide-column / time-series optimized)</li>
  <li><strong>Partition key:</strong> <code>fileId</code></li>
  <li><strong>Sort key:</strong> <code>sequenceNumber</code></li>
</ul>

<h4>In-Memory Cache</h4>
<p>Caches file metadata and recently-accessed file snapshots to avoid repeated Document DB reads. See the CDN &amp; Caching section for full details.</p>

<h4>Object Storage &amp; CDN</h4>
<p>Object Storage holds uploaded assets (images, fonts). The CDN sits in front of it to serve these assets globally with low latency. See the CDN &amp; Caching section for full details.</p>

<!-- ========================== FLOW 2 ========================== -->
<h2 id="flow2">4. Flow 2 ‚Äî Commenting &amp; Notification</h2>
<p>Users can pin comments at specific coordinates on the canvas. Comments exist as threads. Other collaborators see new comments in real time. Users who are tagged or watching the file receive asynchronous notifications (email/push).</p>

<div class="diagram-container">
<pre class="mermaid">
flowchart LR
    A["üë§ Client A<br/>(Commenter)"]
    B["üë§ Client B<br/>(Collaborator<br/>‚Äî online)"]
    C["üë§ Client C<br/>(Mentioned<br/>‚Äî offline)"]

    LB["‚öñÔ∏è Load Balancer"]
    API["üîÄ API Gateway"]
    COMMENT["üí¨ Comment<br/>Service"]
    SQLDB[("üóÑÔ∏è SQL DB<br/>(Comments)")]
    CS["üîÑ Collaboration<br/>Service<br/>(WebSocket)"]
    MQ[("üì® Message Queue")]
    NOTIF["üîî Notification<br/>Service"]
    PUSH["üì± Push / Email<br/>Provider"]

    A -- "1 HTTP POST<br/>/files/:id/comments" --> LB
    LB --> API
    API --> COMMENT
    COMMENT -- "2 Persist<br/>comment" --> SQLDB
    COMMENT -- "3 Publish new_comment<br/>event" --> MQ
    COMMENT -- "4 Return<br/>comment" --> API
    API --> A

    CS -- "5 Broadcast via<br/>WebSocket to online users" --> B

    MQ -- "6 Consume" --> NOTIF
    NOTIF -- "7 Send push /<br/>email to offline" --> PUSH
    PUSH --> C

    COMMENT -- "4b Push via<br/>Pub/Sub" --> CS
</pre>
</div>

<h3>Examples</h3>

<div class="example-card">
<strong>Example 1 ‚Äî Leaving a Comment (Collaborator Online):</strong><br/>
Alice clicks on a button component at canvas coordinates <code>(520, 380)</code> on Page "Home" and types: "The border radius should be 8px, not 4px. @Bob what do you think?" Her browser sends <code>HTTP POST /api/files/abc123/comments</code> with body <code>{ pageId: "page_1", x: 520, y: 380, content: "The border radius should be 8px...", mentions: ["bob_id"] }</code>. The Comment Service persists the comment to the SQL DB and returns the created comment. It also publishes a <code>new_comment</code> event to the Message Queue and notifies the Collaboration Service (via Pub/Sub) to broadcast to connected clients. Bob, who is currently online and connected to the file, sees the comment pin appear on his canvas instantly via WebSocket.
</div>

<div class="example-card">
<strong>Example 2 ‚Äî Notification to Offline User:</strong><br/>
In the above scenario, Bob was mentioned with <code>@Bob</code>. The Message Queue delivers the <code>new_comment</code> event to the Notification Service. The Notification Service checks Bob's notification preferences and, since Bob is mentioned, sends a push notification to his phone and an email: "Alice mentioned you in homepage-v3.fig: 'The border radius should be 8px...'" Bob taps the notification on his phone, which deep-links into the Figma app/browser directly to that comment.
</div>

<div class="example-card">
<strong>Example 3 ‚Äî Resolving a Comment Thread:</strong><br/>
Bob opens the comment thread, replies "Good catch, fixed!", and then clicks "Resolve." The resolve action sends <code>HTTP PATCH /api/files/abc123/comments/cmt_99</code> with body <code>{ resolved: true }</code>. The Comment Service updates the row in the SQL DB. Alice sees the comment thread collapse as resolved in real time.
</div>

<h3>Component Deep Dive ‚Äî Flow 2</h3>

<h4>Comment Service</h4>
<p>Handles all comment CRUD. Comments are relational (they reference a file, a user, a position, a page, and optionally a parent comment for threading).</p>
<ul>
  <li><strong>Protocol:</strong> HTTPS (via API Gateway)</li>
  <li><code>POST /api/files/:fileId/comments</code> ‚Äî Create a comment. Input: <code>{ pageId, x, y, content, mentions[], parentCommentId? }</code>. Output: <code>{ commentId, createdAt, ... }</code></li>
  <li><code>GET /api/files/:fileId/comments</code> ‚Äî List all comments for a file. Input: <code>fileId</code>, optional <code>pageId</code> filter. Output: Array of comment objects with threads.</li>
  <li><code>PATCH /api/files/:fileId/comments/:commentId</code> ‚Äî Update a comment (edit content, resolve). Input: <code>{ content?, resolved? }</code>. Output: Updated comment object.</li>
  <li><code>DELETE /api/files/:fileId/comments/:commentId</code> ‚Äî Delete a comment. Input: <code>commentId</code>. Output: 204 No Content.</li>
</ul>

<h4>Message Queue</h4>
<p>Decouples the Comment Service from the Notification Service. The Comment Service enqueues a <code>new_comment</code> event with the comment payload and list of users to notify. The Notification Service consumes from this queue asynchronously. This ensures that comment creation is not blocked by notification delivery latency.</p>

<h4>Notification Service</h4>
<p>Consumes events from the Message Queue. Checks each user's notification preferences (stored in SQL). Dispatches to the appropriate channel: push notification, email, or in-app notification (stored in a notifications table for later retrieval).</p>
<ul>
  <li><strong>Protocol:</strong> Internal (queue consumer) + push/email provider integration</li>
  <li><code>GET /api/notifications</code> ‚Äî Retrieve a user's notifications. Input: userId (from JWT), pagination. Output: Paginated list of notifications.</li>
</ul>

<!-- ========================== FLOW 3 ========================== -->
<h2 id="flow3">5. Flow 3 ‚Äî Version History</h2>
<p>The system periodically creates snapshots (versions) of the file state. Users can browse version history, preview past versions, name versions, and restore a previous version.</p>

<div class="diagram-container">
<pre class="mermaid">
flowchart LR
    CS["üîÑ Collaboration<br/>Service"]
    VS["üì∏ Version<br/>Service"]
    OPLOG[("üìù Operations Log")]
    SNAP[("üóÉÔ∏è Snapshot Store<br/>(NoSQL)")]
    SQLDB[("üóÑÔ∏è SQL DB<br/>(Version Metadata)")]
    FS["üìÅ File Service"]
    DOCDB[("üìÑ Document DB")]
    A["üë§ Client"]
    API["üîÄ API Gateway"]
    LB["‚öñÔ∏è Load Balancer"]

    CS -- "1 Every N ops or<br/>T minutes ‚Üí trigger" --> VS
    VS -- "2 Read ops<br/>since last snapshot" --> OPLOG
    VS -- "3 Build &<br/>store snapshot" --> SNAP
    VS -- "4 Record version<br/>metadata" --> SQLDB

    A -- "5 GET /files/:id/<br/>versions" --> LB
    LB --> API
    API --> VS
    VS -- "6 Query<br/>version list" --> SQLDB
    VS --> API --> A

    A -- "7 GET /files/:id/<br/>versions/:vId" --> LB
    LB --> API --> VS
    VS -- "8 Load<br/>snapshot" --> SNAP
    VS --> API --> A

    A -- "9 POST /files/:id/<br/>versions/:vId/restore" --> LB
    LB --> API --> VS
    VS -- "10 Copy snapshot<br/>to file data" --> FS
    FS -- "11 Overwrite<br/>current state" --> DOCDB
    VS -- "12 Notify via<br/>Pub/Sub" --> CS
</pre>
</div>

<h3>Examples</h3>

<div class="example-card">
<strong>Example 1 ‚Äî Automatic Snapshot Creation:</strong><br/>
Alice and Bob have been editing <code>homepage-v3.fig</code> for 30 minutes. The Collaboration Service has processed 500 operations since the last snapshot. It triggers the Version Service, which reads operations 1001‚Äì1500 from the Operations Log, applies them to the last known snapshot (at operation 1000) to produce a new materialized state, and stores it in the Snapshot Store. A version metadata entry is written to the SQL DB: <code>{ versionId: "v_37", fileId: "abc123", createdAt: "2025-01-15T14:30:00Z", operationRange: [1001, 1500], autoGenerated: true }</code>.
</div>

<div class="example-card">
<strong>Example 2 ‚Äî Browsing and Previewing History:</strong><br/>
Alice clicks "Version History" in the file menu. Her browser sends <code>GET /api/files/abc123/versions</code>. The Version Service queries the SQL DB and returns a chronological list of version entries with timestamps and creator names. Alice sees 37 versions spanning the past 2 weeks. She clicks on version 25 to preview it. Her browser sends <code>GET /api/files/abc123/versions/v_25</code>. The Version Service loads the snapshot from the Snapshot Store and returns it. Alice's browser renders this snapshot as a read-only preview alongside the current version.
</div>

<div class="example-card">
<strong>Example 3 ‚Äî Restoring a Previous Version:</strong><br/>
Alice decides the design was better at version 25 and clicks "Restore this version." Her browser sends <code>POST /api/files/abc123/versions/v_25/restore</code>. The Version Service loads the snapshot for v_25, then tells the File Service to overwrite the current file data in the Document DB. It also creates a <em>new</em> version entry (v_38) that records this restore action (so the current state is not lost). The Collaboration Service is notified via Pub/Sub, and it pushes the restored state to all connected clients, whose canvases update to reflect the restored design.
</div>

<h3>Component Deep Dive ‚Äî Flow 3</h3>

<h4>Version Service</h4>
<p>Responsible for creating, listing, previewing, and restoring versions.</p>
<ul>
  <li><strong>Protocol:</strong> HTTPS (via API Gateway) + internal gRPC trigger from Collaboration Service</li>
  <li><code>GET /api/files/:fileId/versions</code> ‚Äî List versions. Input: <code>fileId</code>, pagination. Output: <code>[{ versionId, createdAt, createdBy, label? }]</code></li>
  <li><code>GET /api/files/:fileId/versions/:versionId</code> ‚Äî Load a specific version's snapshot for preview. Output: Full node tree snapshot.</li>
  <li><code>POST /api/files/:fileId/versions/:versionId/restore</code> ‚Äî Restore a version. Overwrites current file state and notifies collaborators.</li>
  <li><code>PATCH /api/files/:fileId/versions/:versionId</code> ‚Äî Name/label a version. Input: <code>{ label: "Final review" }</code>.</li>
</ul>

<h4>Snapshot Store</h4>
<p>Stores full materialized file state at a point in time. Each snapshot is a binary-encoded document of the node tree. Keyed by <code>(fileId, versionId)</code>.</p>
<ul>
  <li><strong>Type:</strong> NoSQL (Document) or Object Storage for large snapshots</li>
  <li>Old snapshots can be moved to cheaper cold storage tiers for cost optimization</li>
</ul>

<!-- ========================== FLOW 4 ========================== -->
<h2 id="flow4">6. Flow 4 ‚Äî File Sharing &amp; Permissions</h2>
<p>Users share files with others by granting permissions. Permissions can be granted via email invitation or shareable link. Access is enforced at every entry point.</p>

<div class="diagram-container">
<pre class="mermaid">
flowchart LR
    A["üë§ Owner"]
    B["üë§ Invitee"]
    LB["‚öñÔ∏è Load Balancer"]
    API["üîÄ API Gateway"]
    SHARE["üîó Sharing<br/>Service"]
    AUTH["üîê Auth Service"]
    SQLDB[("üóÑÔ∏è SQL DB<br/>(Permissions)")]
    MQ[("üì® Message Queue")]
    NOTIF["üîî Notification<br/>Service"]
    EMAIL["üìß Email Provider"]

    A -- "1 POST /files/:id/<br/>permissions" --> LB
    LB --> API --> SHARE
    SHARE -- "2 Write<br/>permission" --> SQLDB
    SHARE -- "3 Enqueue<br/>invitation event" --> MQ
    SHARE --> API --> A

    MQ -- "4 Consume" --> NOTIF
    NOTIF -- "5 Send invitation<br/>email" --> EMAIL
    EMAIL --> B

    B -- "6 Click link ‚Üí<br/>GET /files/:id" --> LB
    LB --> API
    API -- "7 Check<br/>permission" --> AUTH
    AUTH -- "8 Query<br/>ACL" --> SQLDB
    AUTH -- "9 Authorized ‚úì" --> API
</pre>
</div>

<h3>Examples</h3>

<div class="example-card">
<strong>Example 1 ‚Äî Sharing via Email Invitation:</strong><br/>
Alice wants Bob to be able to edit <code>homepage-v3.fig</code>. She clicks "Share", types Bob's email, selects "Can edit," and clicks "Send." Her browser sends <code>POST /api/files/abc123/permissions</code> with body <code>{ email: "bob@company.com", role: "editor" }</code>. The Sharing Service resolves Bob's email to a user ID, writes the permission to the SQL DB (<code>file_permissions</code> table), and enqueues a <code>file_shared</code> event. The Notification Service sends Bob an email: "Alice invited you to edit homepage-v3.fig." Bob clicks the link, his JWT is verified, and the Auth Service confirms his <code>editor</code> role on the file by querying the <code>file_permissions</code> table.
</div>

<div class="example-card">
<strong>Example 2 ‚Äî Sharing via Link (View-Only):</strong><br/>
Alice wants to share a view-only link with her manager who doesn't have a Figma account. She clicks "Share" ‚Üí "Copy link" with "Anyone with the link can view." This sends <code>POST /api/files/abc123/permissions</code> with body <code>{ linkAccess: "viewer" }</code>. The Sharing Service updates the file's link access setting in the SQL DB. When the manager opens the link, the Auth Service sees the link access policy allows viewer access, and grants read-only access even without an account.
</div>

<div class="example-card">
<strong>Example 3 ‚Äî Permission Denied:</strong><br/>
Carol, who has no permissions on the file and the link is set to "restricted," tries to open the file URL. The Auth Service queries the <code>file_permissions</code> table, finds no entry for Carol and no open link access, and returns <code>403 Forbidden</code>. Carol sees a "Request access" page.
</div>

<h3>Component Deep Dive ‚Äî Flow 4</h3>

<h4>Sharing Service</h4>
<p>Manages file-level and team-level permissions. Handles invitation workflows and link access settings.</p>
<ul>
  <li><strong>Protocol:</strong> HTTPS (via API Gateway)</li>
  <li><code>POST /api/files/:fileId/permissions</code> ‚Äî Grant permission. Input: <code>{ email or userId, role: "viewer"|"editor"|"owner" }</code> OR <code>{ linkAccess: "viewer"|"editor"|"disabled" }</code>. Output: Updated permissions list.</li>
  <li><code>GET /api/files/:fileId/permissions</code> ‚Äî List current permissions. Output: <code>[{ userId, email, role }]</code> plus link access setting.</li>
  <li><code>DELETE /api/files/:fileId/permissions/:userId</code> ‚Äî Revoke a user's access. Output: 204.</li>
</ul>

<!-- ========================== FLOW 5 ========================== -->
<h2 id="flow5">7. Flow 5 ‚Äî Asset Upload &amp; Export</h2>
<p>Users upload raster images and SVGs into their designs. Users also export frames, groups, or pages as PNG, SVG, PDF, or JPG.</p>

<div class="diagram-container">
<pre class="mermaid">
flowchart LR
    A["üë§ Client"]
    LB["‚öñÔ∏è Load Balancer"]
    API["üîÄ API Gateway"]
    ASSET["üñºÔ∏è Asset<br/>Service"]
    OBJ[("üóÇÔ∏è Object<br/>Storage")]
    CDN["üåê CDN"]
    EXPORT["üì§ Export<br/>Service"]
    QUEUE[("üì® Message<br/>Queue")]

    A -- "1 POST /assets<br/>(multipart upload)" --> LB
    LB --> API --> ASSET
    ASSET -- "2 Store file" --> OBJ
    ASSET -- "3 Return<br/>asset URL" --> API --> A
    A -- "4 Embed<br/>asset in design<br/>(via WebSocket op)" --> A
    CDN -- "5 Serve asset<br/>to all clients" --> OBJ

    A -- "6 POST /files/:id/<br/>export" --> LB
    LB --> API --> EXPORT
    EXPORT -- "7 Enqueue<br/>render job" --> QUEUE
    QUEUE -- "8 Worker picks<br/>up job" --> EXPORT
    EXPORT -- "9 Render &<br/>store result" --> OBJ
    EXPORT -- "10 Return<br/>download URL" --> API --> A
    A -- "11 Download<br/>via CDN" --> CDN
</pre>
</div>

<h3>Examples</h3>

<div class="example-card">
<strong>Example 1 ‚Äî Uploading an Image:</strong><br/>
Alice drags a PNG photo (<code>hero-image.png</code>, 2MB) onto the canvas. Her browser sends <code>POST /api/assets</code> as a multipart form upload with the image binary and metadata <code>{ fileId: "abc123", fileName: "hero-image.png" }</code>. The Asset Service generates a unique key, writes the file to Object Storage, and returns a CDN-backed URL: <code>https://cdn.figma.com/assets/xyz789/hero-image.png</code>. Alice's client then sends a WebSocket operation to the Collaboration Service: <code>{ op: "insert", nodeType: "image", assetUrl: "https://cdn.../hero-image.png", x: 100, y: 200, width: 800, height: 600 }</code>. Bob, who is also connected, receives this operation and his browser fetches the image from the CDN to render it on his canvas.
</div>

<div class="example-card">
<strong>Example 2 ‚Äî Exporting a Frame as PNG:</strong><br/>
Alice selects the "Hero Section" frame and clicks Export ‚Üí PNG @ 2x. Her browser sends <code>POST /api/files/abc123/export</code> with body <code>{ nodeId: "frame_7", format: "png", scale: 2 }</code>. The Export Service enqueues a render job on the Message Queue. A worker picks up the job, loads the file's node tree, renders the specified frame server-side (using a headless rendering engine), produces a 2x PNG, stores it in Object Storage, and returns a signed download URL. Alice's browser auto-downloads the file via the CDN.
</div>

<div class="example-card">
<strong>Example 3 ‚Äî Exporting a Multi-Page PDF:</strong><br/>
Alice selects "Export all pages as PDF." The Export Service receives a job for each page, renders them, combines them into a multi-page PDF, stores it in Object Storage, and returns the download URL. This is an asynchronous operation ‚Äî Alice sees a progress indicator while the export processes.
</div>

<h3>Component Deep Dive ‚Äî Flow 5</h3>

<h4>Asset Service</h4>
<p>Handles uploading, storing, and serving design assets (images, SVGs, fonts).</p>
<ul>
  <li><strong>Protocol:</strong> HTTPS</li>
  <li><code>POST /api/assets</code> ‚Äî Upload an asset. Input: multipart form (file binary + metadata). Output: <code>{ assetId, url }</code>.</li>
  <li><code>DELETE /api/assets/:assetId</code> ‚Äî Delete an asset (garbage collection when no files reference it). Output: 204.</li>
  <li>Assets are served via CDN. The Asset Service only handles writes; reads go through CDN ‚Üí Object Storage.</li>
</ul>

<h4>Export Service</h4>
<p>Renders design nodes into output formats (PNG, SVG, PDF, JPG). This is CPU-intensive and is handled by a pool of worker instances consuming from a Message Queue.</p>
<ul>
  <li><strong>Protocol:</strong> HTTPS (accepts export request) + Message Queue consumer (processes render jobs)</li>
  <li><code>POST /api/files/:fileId/export</code> ‚Äî Request an export. Input: <code>{ nodeIds[], format, scale }</code>. Output: <code>{ jobId }</code> (async) or <code>{ downloadUrl }</code> (sync for small exports).</li>
  <li><code>GET /api/exports/:jobId</code> ‚Äî Poll export status. Output: <code>{ status, downloadUrl? }</code>.</li>
</ul>

<!-- ========================== OVERALL COMBINED DIAGRAM ========================== -->
<h2 id="overall">8. Overall Combined Diagram</h2>
<p>This diagram combines all flows into a single unified architecture view.</p>

<div class="diagram-container">
<pre class="mermaid">
flowchart TB
    subgraph Clients ["üñ•Ô∏è Clients (Browser / Desktop App)"]
        CA["üë§ Client A"]
        CB["üë§ Client B"]
        CC["üë§ Client C"]
    end

    CDN["üåê CDN<br/>(Static Assets, Images, Exports)"]
    LB["‚öñÔ∏è Load Balancer<br/>(L7 ‚Äî HTTP + WebSocket)"]

    subgraph Gateway ["Gateway Layer"]
        API["üîÄ API Gateway<br/>(Rate Limiting, Routing)"]
        AUTH["üîê Auth Service"]
    end

    subgraph Services ["Application Services"]
        FS["üìÅ File Service"]
        SHARE["üîó Sharing Service"]
        COMMENT["üí¨ Comment Service"]
        VS["üì∏ Version Service"]
        ASSET["üñºÔ∏è Asset Service"]
        EXPORT["üì§ Export Service"]
        NOTIF["üîî Notification Service"]
    end

    subgraph RealTime ["Real-Time Layer"]
        CS1["üîÑ Collaboration<br/>Service (Instance 1)"]
        CS2["üîÑ Collaboration<br/>Service (Instance 2)"]
        PS[("üì° Pub/Sub")]
    end

    MQ[("üì® Message Queue")]

    subgraph DataLayer ["Data Layer"]
        CACHE[("üíæ In-Memory Cache")]
        SQLDB[("üóÑÔ∏è SQL DB<br/>(Users, Teams, Projects,<br/>Files metadata, Permissions,<br/>Comments, Notifications)")]
        DOCDB[("üìÑ Document DB<br/>(File Node Trees)")]
        OPLOG[("üìù Operations Log<br/>(Append-Only)")]
        SNAP[("üóÉÔ∏è Snapshot Store")]
        OBJ[("üóÇÔ∏è Object Storage<br/>(Assets, Exports)")]
    end

    PUSH["üì± Push / Email"]

    CA & CB & CC <-->|"HTTP / WSS"| LB
    CA & CB & CC -->|"Asset reads"| CDN
    CDN --> OBJ
    LB --> API
    API <--> AUTH
    AUTH --> SQLDB
    API --> FS & SHARE & COMMENT & VS & ASSET & EXPORT
    FS --> CACHE --> DOCDB
    SHARE --> SQLDB
    COMMENT --> SQLDB
    VS --> OPLOG & SNAP & SQLDB
    ASSET --> OBJ
    EXPORT --> MQ
    MQ --> EXPORT
    COMMENT & SHARE --> MQ
    MQ --> NOTIF
    NOTIF --> PUSH
    NOTIF --> SQLDB
    EXPORT --> OBJ

    LB <-->|"WSS Sticky Sessions"| CS1 & CS2
    CS1 <--> PS <--> CS2
    CS1 & CS2 --> OPLOG
    VS <--> FS
    FS --> DOCDB
</pre>
</div>

<h3>Overall Flow Examples</h3>

<div class="example-card">
<strong>Example ‚Äî Full Session Lifecycle:</strong><br/>
<strong>Step 1 (Share):</strong> Alice creates a new file in her team project. She shares it with Bob (editor) and Carol (viewer) via <code>POST /api/files/:id/permissions</code>. The Sharing Service writes permissions to the SQL DB. Bob and Carol receive email invitations via the Notification Service.<br/><br/>
<strong>Step 2 (Open &amp; Collaborate):</strong> Bob clicks the invitation link. His browser sends <code>GET /api/files/abc123</code> to load the file data from the File Service (which reads from the Document DB via cache). His browser renders the canvas with WebGL and establishes a WebSocket connection to Collaboration Service Instance 1. Alice is already connected to the same instance. Bob draws a rectangle ‚Äî the operation is sent via WebSocket, persisted to the Operations Log, and broadcast to Alice.<br/><br/>
<strong>Step 3 (Upload Asset):</strong> Alice drags an image onto the canvas. It is uploaded via <code>POST /api/assets</code> to the Asset Service ‚Üí Object Storage. The CDN-backed URL is embedded into the design via a WebSocket operation, and Bob's browser fetches the image from the CDN.<br/><br/>
<strong>Step 4 (Comment):</strong> Carol opens the file as a viewer. She notices an issue and leaves a comment: "The spacing between these cards seems off." via <code>POST /api/files/abc123/comments</code>. The Comment Service persists it and publishes to the Message Queue. Alice and Bob see the comment pin appear in real time via WebSocket. Alice gets a push notification because she's the file owner.<br/><br/>
<strong>Step 5 (Version Snapshot):</strong> After 30 minutes of active editing (500 operations), the Collaboration Service triggers the Version Service to create a snapshot. The snapshot is stored in the Snapshot Store, and metadata is written to the SQL DB.<br/><br/>
<strong>Step 6 (Export):</strong> Alice selects the "Hero Section" frame and exports it as PNG @ 2x via <code>POST /api/files/abc123/export</code>. The Export Service queues a render job, a worker renders it, stores the output in Object Storage, and returns a CDN-backed download URL.
</div>

<!-- ========================== DATABASE SCHEMA ========================== -->
<h2 id="schema">9. Database Schema</h2>

<h3>SQL Tables</h3>
<p>SQL is chosen for data that is relational, requires ACID transactions, involves complex queries (joins, filters), and has moderate write throughput. User, team, project, and permission data fit this profile.</p>

<h4>Table: <code>users</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td>Unique user identifier</td></tr>
  <tr><td><code>email</code></td><td>VARCHAR(255)</td><td>UNIQUE, NOT NULL</td><td>Login email</td></tr>
  <tr><td><code>name</code></td><td>VARCHAR(255)</td><td>NOT NULL</td><td>Display name</td></tr>
  <tr><td><code>avatar_url</code></td><td>TEXT</td><td></td><td>CDN URL to profile image</td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> Users are core relational entities referenced by nearly every other table via foreign keys. Read-heavy with low write volume. Needs ACID for account creation/updates.</p>
<p><strong>Reads:</strong> On login, on any profile lookup, on permission checks. <strong>Writes:</strong> On user registration, profile update.</p>
<p><strong>Index:</strong> <span class="tag tag-idx">Hash index on <code>email</code></span> ‚Äî email lookups for login and invitation resolution are exact-match queries, making a hash index ideal (O(1) lookup).</p>

<h4>Table: <code>teams</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td></td></tr>
  <tr><td><code>name</code></td><td>VARCHAR(255)</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>owner_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí users.id</span></td><td>Team creator</td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> Teams are referenced relationally by projects and team_members. Low cardinality, low write volume.</p>
<p><strong>Reads:</strong> When listing teams, opening team dashboard. <strong>Writes:</strong> Team creation, rename.</p>

<h4>Table: <code>team_members</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>team_id</code></td><td>UUID</td><td><span class="tag tag-pk">PK</span> <span class="tag tag-fk">FK ‚Üí teams.id</span></td><td>Composite PK</td></tr>
  <tr><td><code>user_id</code></td><td>UUID</td><td><span class="tag tag-pk">PK</span> <span class="tag tag-fk">FK ‚Üí users.id</span></td><td>Composite PK</td></tr>
  <tr><td><code>role</code></td><td>ENUM('owner','admin','editor','viewer')</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>joined_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> Many-to-many join table. Queried with joins to resolve team membership and permissions. ACID needed for role changes.</p>
<p><strong>Reads:</strong> When checking team-level permissions, listing team members. <strong>Writes:</strong> When inviting/removing team members, changing roles.</p>
<p><strong>Index:</strong> <span class="tag tag-idx">B-tree index on <code>user_id</code></span> ‚Äî to efficiently query "which teams does user X belong to?" (range scan on user_id).</p>

<h4>Table: <code>projects</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td></td></tr>
  <tr><td><code>name</code></td><td>VARCHAR(255)</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>team_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí teams.id</span></td><td></td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>archived</code></td><td>BOOLEAN</td><td>DEFAULT false</td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> Relational to teams and files. Queried with joins. Low volume.</p>
<p><strong>Reads:</strong> When listing projects in a team. <strong>Writes:</strong> Project creation, rename, archive.</p>
<p><strong>Index:</strong> <span class="tag tag-idx">B-tree index on <code>team_id</code></span> ‚Äî to efficiently list all projects for a team.</p>

<h4>Table: <code>files</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td></td></tr>
  <tr><td><code>name</code></td><td>VARCHAR(255)</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>project_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí projects.id</span></td><td></td></tr>
  <tr><td><code>owner_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí users.id</span></td><td></td></tr>
  <tr><td><code>thumbnail_url</code></td><td>TEXT</td><td></td><td>CDN URL</td></tr>
  <tr><td><code>link_access</code></td><td>ENUM('disabled','viewer','editor')</td><td>DEFAULT 'disabled'</td><td>Link sharing policy</td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>updated_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>deleted_at</code></td><td>TIMESTAMP</td><td>NULLABLE</td><td>Soft delete</td></tr>
</table>
<p><strong>Why SQL:</strong> Files are core relational entities with foreign keys to projects and users. Queried with filters (by project, by owner, search by name). Needs ACID for creation/deletion.</p>
<p><strong>Reads:</strong> When listing files in a project, opening a file, searching files. <strong>Writes:</strong> File creation, rename, deletion, thumbnail update, link access change.</p>
<p><strong>Indexes:</strong></p>
<ul>
  <li><span class="tag tag-idx">B-tree index on <code>project_id</code></span> ‚Äî list files in a project (range scan).</li>
  <li><span class="tag tag-idx">B-tree index on <code>owner_id</code></span> ‚Äî list files owned by a user.</li>
  <li><span class="tag tag-idx">B-tree composite index on <code>(project_id, updated_at DESC)</code></span> ‚Äî list files in a project sorted by last modified (common sort order).</li>
</ul>

<h4>Table: <code>file_permissions</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>file_id</code></td><td>UUID</td><td><span class="tag tag-pk">PK</span> <span class="tag tag-fk">FK ‚Üí files.id</span></td><td>Composite PK</td></tr>
  <tr><td><code>user_id</code></td><td>UUID</td><td><span class="tag tag-pk">PK</span> <span class="tag tag-fk">FK ‚Üí users.id</span></td><td>Composite PK</td></tr>
  <tr><td><code>role</code></td><td>ENUM('viewer','editor','owner')</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>granted_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>granted_by</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí users.id</span></td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> ACL data must be consistent (ACID). Queried on every file access. Joins with users table for display.</p>
<p><strong>Reads:</strong> On <em>every</em> file open / API call (authorization check). <strong>Writes:</strong> When sharing/unsharing a file.</p>
<p><strong>Indexes:</strong></p>
<ul>
  <li><span class="tag tag-idx">B-tree index on <code>user_id</code></span> ‚Äî "which files does user X have access to?" (used on the home dashboard).</li>
</ul>
<p><strong>Caching Note:</strong> Because this table is read on every request, permission lookups are cached in the In-Memory Cache with a short TTL (30 seconds). See CDN &amp; Caching section.</p>

<h4>Table: <code>comments</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td></td></tr>
  <tr><td><code>file_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí files.id</span></td><td></td></tr>
  <tr><td><code>user_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí users.id</span></td><td>Author</td></tr>
  <tr><td><code>page_id</code></td><td>VARCHAR(64)</td><td>NOT NULL</td><td>Page within the file</td></tr>
  <tr><td><code>x</code></td><td>FLOAT</td><td>NOT NULL</td><td>Canvas X coordinate</td></tr>
  <tr><td><code>y</code></td><td>FLOAT</td><td>NOT NULL</td><td>Canvas Y coordinate</td></tr>
  <tr><td><code>content</code></td><td>TEXT</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>parent_comment_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí comments.id</span>, NULLABLE</td><td>For threading</td></tr>
  <tr><td><code>resolved</code></td><td>BOOLEAN</td><td>DEFAULT false</td><td></td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> Comments are relational (self-referencing for threads, FK to files and users). Need joins for display (user name + avatar). Moderate read/write volume.</p>
<p><strong>Reads:</strong> When opening a file's comments panel. <strong>Writes:</strong> When creating, editing, resolving, or deleting a comment.</p>
<p><strong>Indexes:</strong></p>
<ul>
  <li><span class="tag tag-idx">B-tree composite index on <code>(file_id, page_id, created_at)</code></span> ‚Äî list comments for a file's page, sorted chronologically.</li>
  <li><span class="tag tag-idx">B-tree index on <code>parent_comment_id</code></span> ‚Äî load replies for a thread.</li>
</ul>

<h4>Table: <code>notifications</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td></td></tr>
  <tr><td><code>user_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí users.id</span></td><td>Recipient</td></tr>
  <tr><td><code>type</code></td><td>ENUM('comment_mention','file_shared','comment_reply', ...)</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>payload</code></td><td>JSONB</td><td>NOT NULL</td><td>Flexible payload for different notification types</td></tr>
  <tr><td><code>read</code></td><td>BOOLEAN</td><td>DEFAULT false</td><td></td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
</table>
<p><strong>Why SQL:</strong> Notifications are read with filters (by user, unread, sorted by time). JSONB provides flexibility for different notification types without schema changes.</p>
<p><strong>Reads:</strong> When user opens notification panel. <strong>Writes:</strong> When Notification Service creates a notification, when user marks as read.</p>
<p><strong>Indexes:</strong></p>
<ul>
  <li><span class="tag tag-idx">B-tree composite index on <code>(user_id, created_at DESC)</code></span> ‚Äî fetch a user's most recent notifications.</li>
  <li><span class="tag tag-idx">B-tree partial index on <code>(user_id) WHERE read = false</code></span> ‚Äî quickly count/fetch unread notifications (filtered index reduces index size).</li>
</ul>

<h4>Table: <code>version_metadata</code></h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>id</code></td><td>UUID</td><td><span class="tag tag-pk">PRIMARY KEY</span></td><td></td></tr>
  <tr><td><code>file_id</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí files.id</span></td><td></td></tr>
  <tr><td><code>label</code></td><td>VARCHAR(255)</td><td>NULLABLE</td><td>User-defined label</td></tr>
  <tr><td><code>operation_seq_start</code></td><td>BIGINT</td><td>NOT NULL</td><td>First operation in this version range</td></tr>
  <tr><td><code>operation_seq_end</code></td><td>BIGINT</td><td>NOT NULL</td><td>Last operation in this version range</td></tr>
  <tr><td><code>snapshot_key</code></td><td>VARCHAR(512)</td><td>NOT NULL</td><td>Key in Snapshot Store</td></tr>
  <tr><td><code>created_by</code></td><td>UUID</td><td><span class="tag tag-fk">FK ‚Üí users.id</span>, NULLABLE</td><td>NULL for auto-generated</td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td>NOT NULL</td><td></td></tr>
  <tr><td><code>is_restore</code></td><td>BOOLEAN</td><td>DEFAULT false</td><td>Whether this was created by a restore action</td></tr>
</table>
<p><strong>Why SQL:</strong> Version metadata is relational (FK to files, users). Needs ordered queries by time. Low write volume (one entry every ~30 min per active file).</p>
<p><strong>Reads:</strong> When user browses version history. <strong>Writes:</strong> When Collaboration Service triggers a snapshot, when user names a version, on restore.</p>
<p><strong>Index:</strong> <span class="tag tag-idx">B-tree composite index on <code>(file_id, created_at DESC)</code></span> ‚Äî list versions for a file in reverse chronological order.</p>

<h3>NoSQL Tables</h3>
<p>NoSQL is chosen for data that is document-structured, requires high write throughput, is append-only, or has flexible/nested schemas that don't fit well in relational tables.</p>

<h4>Table: <code>file_data</code> (Document DB)</h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>file_id</code></td><td>STRING</td><td><span class="tag tag-pk">PARTITION KEY</span></td><td></td></tr>
  <tr><td><code>node_tree</code></td><td>BINARY/DOCUMENT</td><td></td><td>Binary-encoded scene graph: tree of design nodes with all properties</td></tr>
  <tr><td><code>last_operation_seq</code></td><td>BIGINT</td><td></td><td>Sequence number of last operation applied</td></tr>
  <tr><td><code>updated_at</code></td><td>TIMESTAMP</td><td></td><td></td></tr>
</table>
<p><strong>Why Document NoSQL:</strong> The file's node tree is a deeply nested, tree-structured document (frames contain groups contain shapes contain properties). This does not map well to relational rows. A document database stores/retrieves the entire tree as a single unit, which matches the access pattern (read entire file, write entire compacted state). High read/write throughput needed for popular files.</p>
<p><strong>Reads:</strong> When a user opens a file (if not in cache). <strong>Writes:</strong> Periodically when the Collaboration Service compacts the operations log into a new materialized state.</p>
<p><strong>Sharding:</strong> <span class="tag tag-shard">Shard by <code>file_id</code> (hash partitioning)</span>. Each file is an independent unit ‚Äî there are no cross-file queries. Hash partitioning ensures even distribution across shards. This prevents hot spots because popular files are spread across different partitions.</p>

<h4>Table: <code>operations_log</code> (Wide-Column / Time-Series NoSQL)</h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>file_id</code></td><td>STRING</td><td><span class="tag tag-pk">PARTITION KEY</span></td><td></td></tr>
  <tr><td><code>sequence_number</code></td><td>BIGINT</td><td><span class="tag tag-pk">SORT KEY</span></td><td>Monotonically increasing per file</td></tr>
  <tr><td><code>user_id</code></td><td>STRING</td><td></td><td>Who made the operation</td></tr>
  <tr><td><code>operation_data</code></td><td>BINARY</td><td></td><td>Binary-encoded operation (insert/update/delete node + properties)</td></tr>
  <tr><td><code>timestamp</code></td><td>TIMESTAMP</td><td></td><td>Server-assigned time</td></tr>
</table>
<p><strong>Why Wide-Column / Time-Series NoSQL:</strong> The operations log is append-only with extremely high write throughput (every keystroke / mouse drag across all active files). It needs fast sequential reads for replay (reconnection, version building). Wide-column DBs excel at this pattern: write-heavy, time-ordered, partition-key-based access. No need for joins or transactions.</p>
<p><strong>Reads:</strong> On client reconnection (replay missed ops), when Version Service builds a snapshot. <strong>Writes:</strong> On <em>every</em> operation from <em>every</em> client (very high throughput).</p>
<p><strong>Sharding:</strong> <span class="tag tag-shard">Shard by <code>file_id</code> (hash partitioning)</span>. Operations are always read/written within a single file's context. Hash partitioning on <code>file_id</code> distributes the load. Within a partition, data is sorted by <code>sequence_number</code> for efficient range reads.</p>

<div class="warn-card">
<strong>Note on Hot Partitions:</strong> A file with 50 concurrent editors could create a hot partition. Mitigation: The Collaboration Service batches operations (micro-batching every 50ms) and writes them to the log in bulk, reducing the number of individual writes. Additionally, the in-memory CRDT state in the Collaboration Service acts as a write buffer ‚Äî the log is slightly behind real-time but durable.
</div>

<h4>Table: <code>snapshots</code> (Document DB or Object Storage)</h4>
<table>
  <tr><th>Column</th><th>Type</th><th>Constraints</th><th>Notes</th></tr>
  <tr><td><code>file_id</code></td><td>STRING</td><td><span class="tag tag-pk">PARTITION KEY</span></td><td></td></tr>
  <tr><td><code>version_id</code></td><td>STRING</td><td><span class="tag tag-pk">SORT KEY</span></td><td></td></tr>
  <tr><td><code>snapshot_data</code></td><td>BINARY</td><td></td><td>Full materialized node tree at this version</td></tr>
  <tr><td><code>created_at</code></td><td>TIMESTAMP</td><td></td><td></td></tr>
</table>
<p><strong>Why NoSQL / Object Storage:</strong> Snapshots are large binary blobs (can be tens of MB). They are read/written as complete units ‚Äî no partial queries. Access pattern is simple: write a snapshot, read a snapshot by key. Object Storage is ideal for large blobs; alternatively a document DB for smaller snapshots. No relational queries needed.</p>
<p><strong>Reads:</strong> When user previews or restores a version, when building a new snapshot (reads the last snapshot as a base). <strong>Writes:</strong> When Version Service creates a snapshot (every ~30 min per active file).</p>

<h3>Denormalization Decisions</h3>
<div class="card">
<p><strong>Denormalization: <code>files.thumbnail_url</code></strong> ‚Äî The thumbnail could be derived by reading the file data and rendering it. However, generating thumbnails is expensive. So the precomputed thumbnail URL is stored directly in the <code>files</code> table to avoid a join/computation on every file listing. The thumbnail is regenerated asynchronously whenever the file is modified (debounced).</p>
<p><strong>Denormalization: <code>notifications.payload</code> (JSONB)</strong> ‚Äî Instead of normalizing notification data into separate tables for each notification type (comment notifications, sharing notifications, etc.), we use a JSONB column. This avoids the need for multiple joins and allows the notification schema to evolve per-type without migrations. The tradeoff is less strict schema enforcement, which is acceptable for display-only notification data.</p>
<p><strong>Normalization: <code>file_permissions</code> is separate from <code>files</code></strong> ‚Äî Permissions are a many-to-many relationship (many users per file, many files per user). Normalizing this into a separate join table avoids duplicating file data and enables efficient queries in both directions (files for a user, users for a file).</p>
</div>

<!-- ========================== CDN & CACHING ========================== -->
<h2 id="cdn-cache">10. CDN &amp; Caching Deep Dive</h2>

<h3>CDN</h3>
<div class="card">
<p><strong>Appropriate?</strong> Yes ‚Äî CDN is critical for serving static assets (uploaded images, fonts, exported files, file thumbnails) with low latency globally. Figma is used worldwide, and designers embed high-resolution images in their designs. Without a CDN, every asset request would go to the origin Object Storage, adding latency and load.</p>
<p><strong>What is served via CDN:</strong></p>
<ul>
  <li>Uploaded images (PNG, JPG, GIF, SVG) embedded in designs</li>
  <li>Exported files (PNG, PDF, SVG, JPG)</li>
  <li>File thumbnails (shown in the project file browser)</li>
  <li>Static application assets (JS bundles, CSS, WASM modules for the editor)</li>
  <li>Fonts</li>
</ul>
<p><strong>What is NOT served via CDN:</strong></p>
<ul>
  <li>Design file data (node trees) ‚Äî too dynamic, per-user, and large</li>
  <li>Real-time operations ‚Äî served via WebSocket</li>
  <li>API responses ‚Äî served directly by services</li>
</ul>
<p><strong>Cache-Control:</strong> Assets are immutable (content-addressed URLs like <code>/assets/{hash}/image.png</code>). They use <code>Cache-Control: public, max-age=31536000, immutable</code>. If an asset changes, it gets a new URL/hash, so there's no cache invalidation needed.</p>
</div>

<h3>In-Memory Cache</h3>
<div class="card">
<p><strong>Appropriate?</strong> Yes ‚Äî certain data is read extremely frequently and benefits from sub-millisecond access times. The in-memory cache sits between the application services and the databases.</p>

<h4>What is cached:</h4>
<table>
  <tr><th>Data</th><th>Cache Strategy</th><th>Eviction Policy</th><th>Expiration (TTL)</th><th>Rationale</th></tr>
  <tr>
    <td>File metadata (<code>files</code> table rows)</td>
    <td><strong>Cache-aside (Lazy loading)</strong></td>
    <td>LRU</td>
    <td>5 minutes</td>
    <td>File metadata is read on every file open and every file listing. Relatively stable data. Cache-aside is chosen because writes are infrequent ‚Äî we don't need write-through overhead. On a cache miss, the File Service reads from the SQL DB and populates the cache. On a write (rename, etc.), the cache entry is invalidated.</td>
  </tr>
  <tr>
    <td>File data (node tree from Document DB)</td>
    <td><strong>Cache-aside (Lazy loading)</strong></td>
    <td>LRU</td>
    <td>10 minutes</td>
    <td>File data can be large (tens of MB), so only recently-accessed files are cached. This avoids repeated reads from the Document DB when a popular file is opened by many users in quick succession. The Collaboration Service also keeps the active file's CRDT state in its own process memory, so this cache primarily benefits the first load.</td>
  </tr>
  <tr>
    <td>Permission checks (<code>file_permissions</code> lookups)</td>
    <td><strong>Cache-aside (Lazy loading)</strong></td>
    <td>LRU</td>
    <td>30 seconds</td>
    <td>Permissions are checked on every API call. Short TTL ensures permission changes propagate quickly (within 30s). The slight staleness is acceptable ‚Äî a revoked user might have 30 seconds of residual access, which is a reasonable tradeoff for the massive reduction in DB load.</td>
  </tr>
  <tr>
    <td>User sessions / profiles</td>
    <td><strong>Cache-aside</strong></td>
    <td>LRU</td>
    <td>15 minutes</td>
    <td>User profiles are read frequently (avatar + name displayed in presence, comments, etc.). Rarely updated.</td>
  </tr>
</table>

<h4>Why these strategies:</h4>
<ul>
  <li><strong>Cache-aside (Lazy loading)</strong> was chosen over write-through because the system is read-heavy for cached data. Write-through would add latency to every write operation (must write to both cache and DB) but most data doesn't change frequently enough to justify it. Cache-aside only caches data that is actually accessed, avoiding wasting cache space on cold data.</li>
  <li><strong>LRU eviction</strong> is ideal because recently-accessed files are likely to be accessed again (temporal locality). Files being actively edited stay in cache; old files get evicted naturally.</li>
  <li><strong>TTL-based expiration</strong> ensures stale data is eventually refreshed. Different TTLs per data type balance freshness vs. DB load. Permission data gets a short TTL (security-sensitive), while file metadata gets a longer TTL (less sensitive to staleness).</li>
</ul>

<h4>Cache Invalidation:</h4>
<p>On write operations (file rename, permission change, etc.), the service issues a cache <code>DELETE</code> for the affected key. The next read will repopulate the cache from the DB. For distributed cache instances, invalidation events are published via Pub/Sub to ensure all cache nodes evict the stale entry.</p>
</div>

<!-- ========================== WEBSOCKET DEEP DIVE ========================== -->
<h2 id="websocket">11. WebSocket Deep Dive</h2>
<div class="card">
<h4>Why WebSocket?</h4>
<p>Real-time collaborative editing requires bidirectional, low-latency communication. Comparison of alternatives:</p>
<table>
  <tr><th>Approach</th><th>Latency</th><th>Server ‚Üí Client</th><th>Overhead</th><th>Verdict</th></tr>
  <tr><td><strong>WebSocket</strong></td><td>~50ms</td><td>‚úÖ Full duplex</td><td>Low (persistent connection)</td><td>‚úÖ <strong>Selected</strong></td></tr>
  <tr><td>HTTP Polling</td><td>Polling interval (500ms‚Äì5s)</td><td>‚ùå Client must poll</td><td>Very high (repeated HTTP handshakes)</td><td>‚ùå Too slow, too wasteful</td></tr>
  <tr><td>Long Polling</td><td>~100‚Äì200ms</td><td>Simulated push</td><td>High (connection re-establishment)</td><td>‚ùå Too much overhead for 60fps cursors</td></tr>
  <tr><td>Server-Sent Events (SSE)</td><td>~50ms</td><td>‚úÖ Server push</td><td>Low</td><td>‚ùå Unidirectional only ‚Äî client can't send ops back efficiently</td></tr>
  <tr><td>WebRTC (P2P)</td><td>~30ms</td><td>‚úÖ P2P duplex</td><td>Low</td><td>‚ùå No central authority for ordering/persistence. Complex NAT traversal. Doesn't scale to 50 peers.</td></tr>
</table>

<h4>Connection Establishment</h4>
<ol>
  <li>User opens a file ‚Üí Client sends HTTP <code>GET /api/files/:fileId</code> to load file data (normal HTTP).</li>
  <li>After file data is loaded, the client initiates a WebSocket upgrade: <code>GET wss://collab.figma.com/collab/:fileId</code> with headers <code>Authorization: Bearer &lt;JWT&gt;</code> and <code>Upgrade: websocket</code>.</li>
  <li>The Load Balancer (L7) routes this based on <code>fileId</code> hash to a specific Collaboration Service instance (sticky sessions).</li>
  <li>The Collaboration Service validates the JWT (via Auth Service call), verifies file access permissions.</li>
  <li>If authorized, the WebSocket handshake completes (HTTP 101 Switching Protocols).</li>
  <li>The server adds the connection to its in-memory <strong>Connection Registry</strong>: <code>Map&lt;fileId, Set&lt;{userId, socket, cursor, page}&gt;&gt;</code>.</li>
  <li>The server sends a <code>presence_update</code> message to all other connected clients: "Alice joined."</li>
  <li>The server sends the current presence state to the new client: "Bob is on Page 1 at (300, 400)."</li>
</ol>

<h4>Connection Registry</h4>
<p>The Connection Registry is an <strong>in-memory hash map</strong> within each Collaboration Service instance:</p>
<ul>
  <li><strong>Key:</strong> <code>fileId</code></li>
  <li><strong>Value:</strong> Set of <code>{userId, socketRef, cursorPosition, currentPage, lastActivity}</code></li>
</ul>
<p>This is <em>not</em> stored in an external database because it must be accessed at the speed of memory for every incoming operation (which can be dozens per second per file). If an instance crashes, the connections are lost and clients reconnect (which is expected for WebSocket systems).</p>

<h4>Finding Other WebSocket Connections (Cross-Instance)</h4>
<p>When collaborators on the same file are connected to different Collaboration Service instances (due to load balancing), they can't directly communicate. The Pub/Sub system bridges this gap:</p>
<ol>
  <li>Each Collaboration Service instance subscribes to a Pub/Sub channel for every file it hosts: <code>file:{fileId}</code>.</li>
  <li>When an operation arrives on Instance 1, it processes it locally AND publishes it to the <code>file:{fileId}</code> Pub/Sub channel.</li>
  <li>Instance 2 (subscribed to the same channel) receives the message and pushes it to its locally-connected clients for that file.</li>
</ol>
<p>This means the "discovery" of other WebSocket connections is implicit: you don't need to know where they are. You publish to the Pub/Sub channel, and any instance that has relevant clients will relay the message.</p>

<h4>Heartbeat &amp; Disconnection</h4>
<ul>
  <li>The server sends a WebSocket <code>ping</code> frame every 15 seconds. If no <code>pong</code> is received within 5 seconds, the connection is considered dead.</li>
  <li>On disconnection (intentional or timeout), the server removes the entry from the Connection Registry and broadcasts a <code>presence_update</code> ("Alice left") to remaining clients.</li>
  <li>Clients implement exponential backoff reconnection (1s, 2s, 4s, 8s, max 30s). On reconnection, the client sends its last known <code>sequence_number</code>, and the server replays missed operations from the Operations Log.</li>
</ul>

<h4>Message Format</h4>
<p>Messages are sent as <strong>binary (not JSON)</strong> over WebSocket for bandwidth efficiency. A custom binary protocol encodes operation type, node ID, property changes, and timestamps. This reduces payload size by ~60% compared to JSON, which matters when operations are sent at high frequency (e.g., mouse drag = dozens of updates per second).</p>
</div>

<!-- ========================== CRDT DEEP DIVE ========================== -->
<h2 id="crdt">12. CRDT / Conflict Resolution Deep Dive</h2>
<div class="card">
<h4>Why CRDT-inspired approach?</h4>
<p>When multiple users edit the same file simultaneously, conflicts are inevitable. We need a deterministic conflict resolution strategy that guarantees all clients converge to the same state without manual conflict resolution. Two main approaches exist:</p>

<table>
  <tr><th>Approach</th><th>How It Works</th><th>Pros</th><th>Cons</th><th>Verdict</th></tr>
  <tr>
    <td><strong>OT (Operational Transformation)</strong></td>
    <td>Transform operations against each other relative to a central server's canonical order</td>
    <td>Well-understood (Google Docs uses this). Works well for text.</td>
    <td>Requires a single central server per document for ordering. Complex transformation functions for non-text operations. Hard to implement correctly for 2D design operations.</td>
    <td>‚ùå Too complex for design operations</td>
  </tr>
  <tr>
    <td><strong>CRDT (Conflict-free Replicated Data Types)</strong></td>
    <td>Each operation is designed to be commutative and idempotent. Order doesn't matter ‚Äî all clients converge.</td>
    <td>No central server needed for correctness. Better for offline support. Natural fit for property-level updates.</td>
    <td>Higher storage overhead (logical clocks, tombstones). Some semantic conflicts can't be auto-resolved.</td>
    <td>‚úÖ <strong>Selected</strong> (with server-authoritative ordering)</td>
  </tr>
</table>

<h4>Figma's Hybrid Approach</h4>
<p>We use a <strong>server-authoritative CRDT</strong> ‚Äî a hybrid model:</p>
<ul>
  <li>The <strong>data model</strong> is CRDT-based: each design node's properties are modeled as Last-Writer-Wins Registers (LWW-Registers) with Lamport timestamps.</li>
  <li>The <strong>server</strong> assigns a global sequence number to each operation, providing a total ordering.</li>
  <li>Clients apply operations in server-assigned order. If two operations conflict on the same property of the same node, the one with the higher sequence number wins.</li>
</ul>

<h4>Conflict Resolution Rules</h4>
<ol>
  <li><strong>Same property, same node:</strong> Last-Writer-Wins (LWW) based on server sequence number. Example: Alice sets <code>rect.x = 200</code> (seq 47), Bob sets <code>rect.x = 400</code> (seq 48) ‚Üí result is <code>400</code>.</li>
  <li><strong>Different properties, same node:</strong> No conflict. Both are applied. Example: Alice sets <code>rect.x = 200</code>, Bob sets <code>rect.fill = red</code> ‚Üí both applied.</li>
  <li><strong>Different nodes:</strong> No conflict. Both applied independently.</li>
  <li><strong>Create + delete conflict:</strong> If Alice creates a child of node X while Bob deletes node X, the server uses a "delete wins" policy ‚Äî the child creation is effectively orphaned and garbage-collected. Alternatively, a "create wins" policy could restore the parent.</li>
  <li><strong>Tree restructuring:</strong> If Alice moves node A into group B while Bob moves group B into node A (creating a cycle), the server detects the cycle and rejects the later operation.</li>
</ol>

<h4>CRDT State Representation</h4>
<p>Each design node is represented as:</p>
<pre><code>{
  nodeId: "rect_42",
  type: "RECTANGLE",
  parent: "frame_1",
  properties: {
    x: { value: 200, clock: 47, userId: "alice" },
    y: { value: 150, clock: 45, userId: "alice" },
    width: { value: 300, clock: 12, userId: "bob" },
    fill: { value: "#FF0000", clock: 48, userId: "bob" }
  }
}</code></pre>
<p>Each property has an LWW-Register with the value, logical clock (Lamport timestamp), and last writer. The <code>clock</code> values correspond to the server-assigned sequence numbers.</p>
</div>

<!-- ========================== PUB/SUB DEEP DIVE ========================== -->
<h2 id="pubsub">13. Pub/Sub Deep Dive</h2>
<div class="card">
<h4>Why Pub/Sub?</h4>
<p>The Collaboration Service is horizontally scaled ‚Äî multiple instances run behind a Load Balancer. Users editing the same file may be connected to different instances. We need a mechanism for cross-instance communication. Pub/Sub provides this:</p>
<ul>
  <li><strong>Publishers:</strong> Collaboration Service instances publish operations and presence updates to a channel when they receive them from a connected client.</li>
  <li><strong>Subscribers:</strong> All Collaboration Service instances subscribe to channels for the files they host. When a message arrives on a channel, the instance pushes it to its locally-connected clients.</li>
</ul>

<h4>Why Pub/Sub over alternatives?</h4>
<table>
  <tr><th>Alternative</th><th>Issue</th></tr>
  <tr><td>Direct instance-to-instance communication</td><td>Requires service discovery and N-to-N connections. Doesn't scale. Complex routing logic.</td></tr>
  <tr><td>Message Queue (point-to-point)</td><td>Messages are consumed by one consumer only. We need fan-out to ALL instances hosting the file.</td></tr>
  <tr><td>Shared database polling</td><td>Too slow. Polling interval adds latency. Not suitable for real-time.</td></tr>
</table>

<h4>Channel Structure</h4>
<ul>
  <li><strong>Operations channel:</strong> <code>file:ops:{fileId}</code> ‚Äî carries design operations (node create/update/delete).</li>
  <li><strong>Presence channel:</strong> <code>file:presence:{fileId}</code> ‚Äî carries cursor positions, selections, page changes, join/leave events. Separated from operations because presence updates are higher frequency but lower importance (can be dropped without harm).</li>
</ul>

<h4>How it works:</h4>
<ol>
  <li>When a Collaboration Service instance starts hosting a file (first client connects for that file), it subscribes to <code>file:ops:{fileId}</code> and <code>file:presence:{fileId}</code>.</li>
  <li>When the last client disconnects from that file on an instance, the instance unsubscribes from both channels (cleanup).</li>
  <li>When an operation arrives from a client, the instance: (a) processes it locally, (b) publishes to <code>file:ops:{fileId}</code>.</li>
  <li>Other subscribed instances receive the published message and push it to their locally-connected clients for that file.</li>
  <li>Messages include the <code>sourceInstanceId</code> so that the publishing instance can ignore its own messages (no echo).</li>
</ol>

<h4>Reliability</h4>
<p>Pub/Sub is used for real-time relay, not durability. Operations are also persisted to the Operations Log. If a Pub/Sub message is lost (rare), clients will catch up on the next periodic sync or reconnection.</p>
</div>

<!-- ========================== MESSAGE QUEUE DEEP DIVE ========================== -->
<h3>Message Queue (Separate from Pub/Sub)</h3>
<div class="card">
<p>A separate <strong>Message Queue</strong> (point-to-point, durable) is used for asynchronous job processing that does NOT require real-time fan-out:</p>
<ul>
  <li><strong>Notification delivery:</strong> Comment creation ‚Üí enqueue notification job ‚Üí Notification Service consumes and sends email/push.</li>
  <li><strong>Export rendering:</strong> Export request ‚Üí enqueue render job ‚Üí Export worker consumes, renders, stores result.</li>
  <li><strong>Thumbnail generation:</strong> File change ‚Üí debounced thumbnail re-render job.</li>
</ul>
<p><strong>Why a Message Queue (not Pub/Sub)?</strong> These jobs must be processed <em>exactly once</em> (or at-least-once with idempotency). A message queue with consumer groups and acknowledgment ensures each job is picked up by exactly one worker. Pub/Sub's fan-out semantics would process the same job on every subscriber, which is wrong for these use cases.</p>
<p><strong>How messages are enqueued:</strong> The producing service (e.g., Comment Service) serializes the event payload and calls the queue's <code>enqueue(queueName, messagePayload)</code> API.</p>
<p><strong>How messages are dequeued:</strong> Worker services poll the queue or maintain long-poll connections. When a message is received, the worker processes it and sends an acknowledgment (<code>ack</code>). If the worker fails to ack within a timeout, the message is redelivered to another worker (at-least-once semantics). Workers are designed to be idempotent.</p>
</div>

<!-- ========================== LOAD BALANCERS ========================== -->
<h2 id="lb">14. Load Balancers</h2>
<div class="card">
<h4>Where Load Balancers Are Placed</h4>
<ol>
  <li><strong>External Load Balancer (Internet-facing):</strong> Sits between the clients and the API Gateway / Collaboration Service. All inbound traffic from browsers/desktop apps hits this load balancer first. It terminates TLS, performs health checks, and routes traffic.</li>
  <li><strong>Internal Load Balancer:</strong> Sits between the API Gateway and internal microservices (File Service, Comment Service, etc.). Routes internal gRPC calls. Uses round-robin since internal services are stateless.</li>
</ol>

<h4>External Load Balancer ‚Äî Deep Dive</h4>
<ul>
  <li><strong>Layer:</strong> L7 (Application Layer) ‚Äî needs to inspect HTTP headers and WebSocket upgrade requests.</li>
  <li><strong>HTTP traffic routing:</strong> Round-robin or least-connections to API Gateway instances.</li>
  <li><strong>WebSocket traffic routing:</strong> <strong>Consistent hashing on <code>fileId</code></strong> (extracted from the URL path <code>/collab/:fileId</code>). This ensures that all clients editing the same file are preferentially routed to the same Collaboration Service instance, minimizing the need for Pub/Sub relay. When an instance is added/removed, consistent hashing minimizes remapping.</li>
  <li><strong>Health checks:</strong> Periodic HTTP GET to <code>/health</code> on each backend instance. Unhealthy instances are removed from the pool.</li>
  <li><strong>SSL/TLS termination:</strong> TLS is terminated at the load balancer. Internal traffic between the LB and services can use unencrypted connections within a trusted network (or mTLS for extra security).</li>
  <li><strong>Connection draining:</strong> When a Collaboration Service instance is being shut down (for deployment), existing WebSocket connections are allowed to drain (complete or gracefully disconnect) before the instance is removed. New connections are routed elsewhere.</li>
</ul>

<h4>Internal Load Balancer</h4>
<ul>
  <li><strong>Layer:</strong> L4 or L7 ‚Äî routes gRPC/HTTP calls to service instances.</li>
  <li><strong>Routing:</strong> Round-robin ‚Äî all internal services are stateless (state is in databases/cache).</li>
  <li><strong>Used between:</strong> API Gateway ‚Üî File/Comment/Sharing/Version/Asset/Export/Auth services.</li>
</ul>
</div>

<!-- ========================== SCALING CONSIDERATIONS ========================== -->
<h2 id="scaling">15. Scaling Considerations</h2>
<div class="card">

<h4>Collaboration Service (Most Critical)</h4>
<ul>
  <li><strong>Horizontal scaling:</strong> Add more instances behind the Load Balancer. Consistent hashing on <code>fileId</code> distributes files across instances.</li>
  <li><strong>Scaling trigger:</strong> Number of concurrent WebSocket connections, CPU usage (CRDT operations), memory usage (in-memory file state).</li>
  <li><strong>Limit:</strong> Each instance can handle ~10,000‚Äì50,000 concurrent connections depending on activity level. Scale based on active connections, not just total connections.</li>
  <li><strong>Memory management:</strong> If a file has no active connections for 5 minutes, evict its CRDT state from memory. Reload from Document DB + Operations Log replay on the next connection.</li>
</ul>

<h4>API Gateway</h4>
<ul>
  <li>Stateless ‚Äî scales horizontally with the external Load Balancer distributing traffic via round-robin.</li>
  <li>Auto-scale based on request rate and latency.</li>
</ul>

<h4>File Service, Comment Service, Sharing Service, etc.</h4>
<ul>
  <li>All stateless microservices. Scale horizontally behind the internal Load Balancer based on request rate.</li>
  <li>Read replicas for the SQL DB can be introduced when read traffic exceeds the primary's capacity.</li>
</ul>

<h4>Export Service</h4>
<ul>
  <li>CPU-intensive (rendering). Scale with worker pools consuming from the Message Queue.</li>
  <li>Auto-scale based on queue depth (number of pending export jobs). If queue depth > threshold, spin up more workers.</li>
</ul>

<h4>SQL Database</h4>
<ul>
  <li><strong>Vertical scaling first</strong> (larger instance), then <strong>read replicas</strong> for read-heavy tables (files, permissions, comments).</li>
  <li>If write throughput becomes a bottleneck, consider <strong>sharding</strong> the <code>files</code> and <code>comments</code> tables by <code>team_id</code> (team-based sharding groups related data together).</li>
  <li>The <code>notifications</code> table can be sharded by <code>user_id</code> since notifications are always read per-user.</li>
</ul>

<h4>Document DB / Operations Log</h4>
<ul>
  <li>Already sharded by <code>file_id</code>. Scale by adding more partitions/nodes to the cluster.</li>
  <li>Operations Log is append-only and can leverage compaction: periodically, old operations that have been rolled into a snapshot can be archived to cold storage.</li>
</ul>

<h4>In-Memory Cache</h4>
<ul>
  <li>Scale by adding more cache nodes in a cluster (distributed cache with consistent hashing).</li>
  <li>Scale trigger: cache hit rate < 90%, memory utilization > 80%.</li>
</ul>

<h4>Object Storage &amp; CDN</h4>
<ul>
  <li>Object Storage scales inherently (managed service). No scaling concern.</li>
  <li>CDN scales inherently via global edge nodes. Monitor cache hit ratio ‚Äî if it drops, review cache headers.</li>
</ul>

<h4>Pub/Sub</h4>
<ul>
  <li>Scale by adding more Pub/Sub nodes/shards. The load is proportional to the number of active files √ó number of Collaboration Service instances per file.</li>
</ul>

<h4>Load Balancer Scaling Summary</h4>
<table>
  <tr><th>Location</th><th>Type</th><th>Scaling</th></tr>
  <tr><td>Between clients and API Gateway + Collaboration Service</td><td>External L7 LB</td><td>Horizontal auto-scaling, multiple LB instances behind DNS round-robin or anycast</td></tr>
  <tr><td>Between API Gateway and internal microservices</td><td>Internal L4/L7 LB</td><td>Horizontal auto-scaling based on internal traffic volume</td></tr>
</table>
</div>

<!-- ========================== TRADEOFFS ========================== -->
<h2 id="tradeoffs">16. Tradeoffs &amp; Deep Dives</h2>
<div class="card">

<h4>Tradeoff 1: Server-Authoritative CRDT vs. Pure CRDT</h4>
<p><strong>Decision:</strong> Server-authoritative (server assigns global order).</p>
<p><strong>Tradeoff:</strong> A pure CRDT wouldn't need the server for ordering ‚Äî clients could resolve conflicts locally. However, the server-authoritative model gives us: (a) a single source of truth for sequence numbers, simplifying reasoning; (b) the ability to validate operations server-side (prevent invalid state); (c) simpler client implementation. The cost is that the server is a dependency for operation ordering, but since we need the server for persistence anyway, this is an acceptable trade.</p>

<h4>Tradeoff 2: Last-Writer-Wins for Property Conflicts</h4>
<p><strong>Decision:</strong> LWW for same-property conflicts.</p>
<p><strong>Tradeoff:</strong> LWW means one user's change "wins" and the other's is lost. For design tools, this is acceptable because: (a) property-level conflicts are rare (designers work on different areas of the canvas); (b) the "losing" operation is visible in version history and can be recovered; (c) more sophisticated conflict resolution (like multi-value registers) would create confusing UX ("which value do you want?"). The risk is that a user's change is silently overwritten, but Figma's multi-cursor presence system makes users aware of each other, reducing the chance of conflicts.</p>

<h4>Tradeoff 3: Binary Protocol vs. JSON over WebSocket</h4>
<p><strong>Decision:</strong> Custom binary protocol.</p>
<p><strong>Tradeoff:</strong> Binary encoding reduces payload size by ~60% and parse time significantly, which matters for high-frequency operations (cursor moves at 60fps). The cost is complexity: a custom encoder/decoder must be maintained on both client and server, debugging is harder (not human-readable), and third-party tooling can't inspect messages easily. Accepted because the performance gain is critical for the user experience.</p>

<h4>Tradeoff 4: Sticky Sessions for WebSocket vs. Stateless Routing</h4>
<p><strong>Decision:</strong> Sticky sessions (consistent hashing on fileId).</p>
<p><strong>Tradeoff:</strong> Sticky sessions reduce the need for Pub/Sub relay (if all editors of a file are on the same instance, Pub/Sub is not needed for that file). The cost is uneven load distribution ‚Äî a popular file with 50 editors all lands on one instance. Mitigated by: (a) Pub/Sub as a fallback (if an instance is full, overflow connections go to another instance and communicate via Pub/Sub); (b) monitoring and rebalancing.</p>

<h4>Tradeoff 5: Operations Log (Append-Only) + Periodic Snapshots vs. Always Writing Full State</h4>
<p><strong>Decision:</strong> Append-only log + periodic snapshot compaction.</p>
<p><strong>Tradeoff:</strong> Writing only the delta (operation) is fast and efficient. But reading the file requires loading the last snapshot and replaying subsequent operations. This is slower than just reading a single full state document. Mitigated by frequent snapshots (every ~30 minutes or 500 operations), which keep the replay window small. The alternative ‚Äî writing the full state on every operation ‚Äî would be prohibitively expensive for files with 100K+ nodes being edited at high frequency.</p>

<h4>Tradeoff 6: SQL for Metadata vs. All-NoSQL</h4>
<p><strong>Decision:</strong> SQL for relational metadata, NoSQL for file data and operations.</p>
<p><strong>Tradeoff:</strong> SQL provides ACID transactions, strong consistency, and relational joins ‚Äî essential for permissions, user management, and organizational data. NoSQL provides the write throughput and flexible schema needed for operations and design data. The cost is managing two database technologies. An all-NoSQL approach would simplify operations but make permission checks and organizational queries much harder (no joins). An all-SQL approach would struggle with the write throughput of the operations log.</p>
</div>

<!-- ========================== ALTERNATIVES ========================== -->
<h2 id="alternatives">17. Alternative Approaches</h2>
<div class="card">

<h4>Alternative 1: WebRTC for Peer-to-Peer Collaboration</h4>
<p><strong>Approach:</strong> Clients communicate directly with each other using WebRTC data channels, bypassing the server for real-time operations.</p>
<p><strong>Why not chosen:</strong> (a) No central authority for operation ordering ‚Üí harder conflict resolution. (b) P2P doesn't scale to 50 concurrent editors (mesh topology = N¬≤ connections). (c) NAT traversal failures are common in corporate networks. (d) No central persistence ‚Äî if all clients disconnect, unsaved work is lost. (e) Server-side validation (permission checks, cycle detection) is impossible. WebRTC is better suited for audio/video streaming (where occasional packet loss is tolerable), not for document collaboration requiring total ordering and durability.</p>

<h4>Alternative 2: Operational Transformation (OT) Instead of CRDT</h4>
<p><strong>Approach:</strong> Use Google Docs-style OT where operations are transformed against each other relative to a shared history.</p>
<p><strong>Why not chosen:</strong> OT works well for linear text documents (insert/delete at position). For 2D design operations (move node, resize, change parent, boolean operations), the transformation functions become extremely complex and error-prone. OT also requires a strict centralized ordering server per document ‚Äî while we do use server-authoritative ordering, the CRDT-based data model (LWW registers per property) is simpler to implement and reason about for property-level updates. OT would be considered if the product were primarily a text editor.</p>

<h4>Alternative 3: Polling-Based Collaboration</h4>
<p><strong>Approach:</strong> Clients periodically poll the server for changes (e.g., every 500ms).</p>
<p><strong>Why not chosen:</strong> 500ms polling latency makes cursor movements and real-time editing feel sluggish and disconnected. It also generates enormous unnecessary server load (millions of "no changes" responses). WebSockets provide sub-50ms propagation with minimal overhead. Polling might be acceptable for a simpler collaborative tool (like Google Sheets), but not for a real-time design tool where visual feedback must be immediate.</p>

<h4>Alternative 4: Single Monolithic Service Instead of Microservices</h4>
<p><strong>Approach:</strong> One large service handles file management, collaboration, comments, exports, etc.</p>
<p><strong>Why not chosen:</strong> The Collaboration Service has very different scaling and resource characteristics (long-lived WebSocket connections, high memory for CRDT state, CPU for operation processing) compared to the Export Service (CPU-intensive, bursty, stateless) or the Comment Service (standard CRUD). Microservices allow each to scale independently. The Collaboration Service can scale based on connections while the Export Service scales based on queue depth. The cost of microservices (network overhead, operational complexity) is justified by the diversity of workload types.</p>

<h4>Alternative 5: File Locking Instead of Concurrent Editing</h4>
<p><strong>Approach:</strong> Only one user can edit a file at a time. Other users see a read-only view. (This is how traditional desktop design tools like Sketch work with shared files.)</p>
<p><strong>Why not chosen:</strong> This defeats the core value proposition of Figma ‚Äî real-time collaboration. Designers frequently co-create, do live reviews, and pair-design. File locking creates workflow bottlenecks and leads to version conflicts when locks are released. The complexity of CRDT-based concurrent editing is justified because it enables the product's primary differentiator.</p>

<h4>Alternative 6: Git-Style Branching and Merging</h4>
<p><strong>Approach:</strong> Each user edits their own "branch" of the file and merges changes later.</p>
<p><strong>Why not chosen:</strong> Design files are visual, and merge conflicts in visual content are extremely difficult to resolve (what does it mean to merge two different layouts?). Real-time collaboration with immediate convergence is a better UX for design work. Branching could be offered as an additional feature (e.g., Figma's "Branching" feature for design review workflows), but it should not replace real-time collaboration.</p>
</div>

<!-- ========================== ADDITIONAL INFO ========================== -->
<h2 id="additional">18. Additional Information</h2>
<div class="card">

<h4>Client-Side Rendering Architecture</h4>
<p>Figma renders the canvas using <strong>WebGL</strong> (not the DOM). This is essential because design files can contain tens of thousands of vector objects. DOM-based rendering would create an equal number of DOM nodes, causing layout and paint performance to collapse. WebGL allows the client to batch-render all objects in a single GPU draw call sequence, maintaining 60fps even with complex designs.</p>
<p>The rendering pipeline is: <strong>CRDT State (scene graph) ‚Üí Render Tree ‚Üí GPU Commands ‚Üí WebGL Canvas</strong>. Only the CRDT state is synchronized ‚Äî the rendering is entirely local. This means the server never needs to render the design (except for exports and thumbnails).</p>

<h4>Offline Support</h4>
<p>Limited offline support is possible because the client holds the full file state in memory. If the WebSocket disconnects, the user can continue editing. Operations are buffered locally. When connectivity resumes, the buffer is flushed to the server, and any server-side operations are replayed. Because the data model is CRDT-based, this reconciliation is guaranteed to converge. However, offline mode is inherently limited ‚Äî the user cannot see others' changes and collaboration is paused.</p>

<h4>Thumbnail Generation</h4>
<p>When a file is modified, a debounced (5-minute delay) background job re-renders the file's first page as a thumbnail image and uploads it to Object Storage. The <code>files.thumbnail_url</code> is updated. This ensures the file browser always shows a recent preview without requiring real-time rendering.</p>

<h4>Component Overrides &amp; Propagation</h4>
<p>When a main component is updated, all instances of that component must reflect the change (except for properties the instance has overridden). This is handled client-side: the instance nodes in the scene graph reference their main component and compute their effective properties as <code>mainComponentProps.merge(overrides)</code>. The server does not resolve overrides ‚Äî it only stores the raw override data. This is a form of computed denormalization: the "effective state" is computed on-read (client-side) from the normalized stored data.</p>

<h4>Rate Limiting &amp; Abuse Prevention</h4>
<p>The API Gateway applies rate limiting per user (e.g., 100 API requests/second, 50 export requests/hour). The Collaboration Service applies operation rate limiting per connection (e.g., 60 operations/second per client ‚Äî roughly matching the frame rate). Operations exceeding the rate are queued or dropped (for non-critical updates like cursor moves).</p>

<h4>Security ‚Äî WebSocket Authentication</h4>
<p>The WebSocket connection is authenticated using the JWT provided in the initial HTTP upgrade request. The JWT's expiration is checked periodically (every 5 minutes). If the JWT has expired, the server sends a <code>reauthenticate</code> message, prompting the client to obtain a fresh token and send it over the existing WebSocket (avoiding disconnection). If re-authentication fails, the connection is closed.</p>

<h4>File Size Limits &amp; Performance Budgets</h4>
<p>Files with more than 100K nodes are flagged as "large files." The system applies performance mitigations: lazy loading of pages (only the active page's data is loaded initially), reduced presence update frequency, and more aggressive operation batching. An in-product warning encourages the user to split the file.</p>
</div>

<!-- ========================== VENDORS ========================== -->
<h2 id="vendors">19. Vendor Section</h2>
<div class="card">
<p>Below are potential vendor choices for the vendor-agnostic components described in this design. These are recommendations based on the access patterns and requirements identified above.</p>

<table>
  <tr><th>Component</th><th>Vendor Options</th><th>Rationale</th></tr>
  <tr>
    <td><strong>SQL Database</strong></td>
    <td>PostgreSQL, CockroachDB, Amazon Aurora</td>
    <td><strong>PostgreSQL</strong> is the most common choice for relational data with JSONB support (for the <code>notifications.payload</code> column). Mature, excellent indexing, strong ACID guarantees. <strong>CockroachDB</strong> if global distribution and horizontal scaling of SQL is needed without manual sharding. <strong>Aurora</strong> for managed MySQL/PostgreSQL with auto-scaling read replicas.</td>
  </tr>
  <tr>
    <td><strong>Document DB (File Data)</strong></td>
    <td>MongoDB, Amazon DocumentDB, Couchbase</td>
    <td><strong>MongoDB</strong> is ideal for the file data store ‚Äî it natively handles nested document structures (the design node tree), supports binary data, and can handle large documents. Good sharding support with hash-based partitioning on <code>file_id</code>.</td>
  </tr>
  <tr>
    <td><strong>Wide-Column DB (Operations Log)</strong></td>
    <td>Apache Cassandra, ScyllaDB, Amazon DynamoDB</td>
    <td><strong>Cassandra/ScyllaDB</strong> excel at high write throughput, append-only workloads with time-ordered data. Partition by <code>file_id</code>, cluster by <code>sequence_number</code>. Tunable consistency. <strong>DynamoDB</strong> for a fully managed option with similar partition/sort key semantics.</td>
  </tr>
  <tr>
    <td><strong>In-Memory Cache</strong></td>
    <td>Redis, Memcached, Dragonfly</td>
    <td><strong>Redis</strong> offers rich data structures (hashes for cached objects, sorted sets for ordered data, pub/sub built-in). The Pub/Sub feature of Redis could also be used for the cross-instance Pub/Sub. <strong>Memcached</strong> if simpler key-value caching is sufficient. <strong>Dragonfly</strong> as a high-performance Redis alternative.</td>
  </tr>
  <tr>
    <td><strong>Pub/Sub</strong></td>
    <td>Redis Pub/Sub, Apache Kafka, NATS</td>
    <td><strong>Redis Pub/Sub</strong> for simplicity if Redis is already used for caching (one less system). Low latency but fire-and-forget (no durability ‚Äî acceptable since operations are persisted separately). <strong>NATS</strong> for ultra-low-latency pub/sub with better clustering. <strong>Kafka</strong> if durability and replay are needed at the pub/sub layer (overkill for this use case since operations are durably logged separately).</td>
  </tr>
  <tr>
    <td><strong>Message Queue</strong></td>
    <td>RabbitMQ, Amazon SQS, Apache Kafka</td>
    <td><strong>RabbitMQ</strong> for traditional message queuing with acknowledgments, dead-letter queues, and routing. Good for the notification and export job workloads. <strong>SQS</strong> for a fully managed, highly durable option. <strong>Kafka</strong> if the message queue also needs to serve as an event log.</td>
  </tr>
  <tr>
    <td><strong>Object Storage</strong></td>
    <td>Amazon S3, Google Cloud Storage, MinIO</td>
    <td><strong>S3/GCS</strong> are industry standards for blob storage ‚Äî highly durable (11 9s), scalable, with lifecycle policies for tiering old snapshots to cheaper storage. <strong>MinIO</strong> for self-hosted S3-compatible storage.</td>
  </tr>
  <tr>
    <td><strong>CDN</strong></td>
    <td>Cloudflare, Amazon CloudFront, Fastly</td>
    <td><strong>Cloudflare</strong> for global edge network with excellent performance and built-in DDoS protection. <strong>CloudFront</strong> for tight integration with S3. <strong>Fastly</strong> for real-time cache purging capabilities.</td>
  </tr>
  <tr>
    <td><strong>Load Balancer</strong></td>
    <td>NGINX, HAProxy, AWS ALB, Envoy</td>
    <td><strong>NGINX/HAProxy</strong> for self-managed L7 load balancing with WebSocket support and consistent hashing. <strong>Envoy</strong> for service mesh integration. <strong>AWS ALB</strong> for managed L7 with native WebSocket support and sticky sessions.</td>
  </tr>
</table>
</div>

<script>
  mermaid.initialize({
    startOnLoad: true,
    theme: 'default',
    flowchart: {
      useMaxWidth: true,
      htmlLabels: true,
      curve: 'basis'
    },
    securityLevel: 'loose'
  });
</script>

</body>
</html>
